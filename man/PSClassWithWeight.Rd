% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PSClassWithWeights.R
\name{PSClassWithWeight}
\alias{PSClassWithWeight}
\title{PS score calculation and binary classification for a testing data set without PStraining output object, but with selected feature weights}
\usage{
PSClassWithWeight(newdat, weights, classProbCut = 0.8,
  PShighGroup = "PShigh", PSlowGroup = "PSlow", breaks = 50,
  imputeNA = FALSE, byrow = TRUE, imputeValue = c("median", "mean"))
}
\arguments{
\item{newdat}{a new data matrix or data frame, columns for samples and rows for features}

\item{weights}{a numeric vector with selected features (as names of the vector) and their weights}

\item{classProbCut}{a numeric variable within (0,1), which is a cutoff of Empirical Bayesian probability, 
often used values are 0.8 and 0.9, default value is 0.8. Only one value is used for both groups, 
the samples that are not included in either group will be assigned as UNCLASS}

\item{PShighGroup}{a string to indicate group name with high PS score}

\item{PSlowGroup}{a string to indicate group name with low PS score}

\item{breaks}{a integer to indicate number of bins in histogram, default is 50}

\item{imputeNA}{a logic variable to indicate if NA imputation is needed, if it is TRUE, NA imputation is 
processed before any other steps, the default is FALSE}

\item{byrow}{a logic variable to indicate direction for imputation, default is TRUE, 
which will use the row data for imputation}

\item{imputeValue}{a character variable to indicate which value to be used to replace NA, default is "median", 
the median value of the chose direction with "byrow" data to be used}
}
\value{
A data frame with PS score, Empirical Bayesian probabilites for two groups and classification
}
\description{
This is the function to calculate PS (Prediction Strength) scores for a testing data set 
without PS training object. However, we do need selected feature list with their weights, and mean of two group means for each
selected feature that we need to apply EM (Expectation-Maximization) to achieve. Once we have PS scores, we could use the 
theoretic natual cutoff 0 to make classification calls. Alternatively, we can also apply EM to calcualate mean and sd for the two groups 
assuming that PS score is a mixture of two normal distributions, followed by Empirical Bayes' probability calculation and final binary classification calls.
}
\details{
This is the function to calculate PS scores and make classification based on
Empirical Bayesian probabilities for a testing new data set. Before we do anything, we need to do standardization,
which is requred before PS calculation. 
PS calculation is based on:
\eqn{PS = (V_win âˆ’ V_lose)/(V_win + V_lose)}
Here, where V_win and V_lose are the vote totals for the winning and losing features/traits for a given sample
tp get these vote, however, we need to know mean of two group means for each selected features. In oder to get achieve them,
there are multiple ways to do, in this function, we apply EM algorithm on each input feature data to obtain, and further
to get PS score for each sample. Once we have PS scores, we can use PS natual therotic cutoff 0 to make classification calls.
Alternatively, we can make calls based on Empirical Bayes' probability. To do that, 
we also need to apply EM to get PS score mean and sd for two groups. 
After that, we can calcualte probability that a sample belongs to either group,
and then use the following formula to get Empirical Bayes' probability:
\eqn{prob(x) = p_test(x)/(p_test(x) + p_ref(x))}
Here prob(x) is the Empirical Bayes' probability of a given sample, p_test(x) is the probability that a given sample
belongs to the test group, p_ref(x) is the probability that a given sample belongs to the reference group.
Notice that the test and reference group is just the relative grouping, in fact, for this step, we often need
 to calculate Empirical Bayes' probabilities for a given sample from two different standing points.
}
\references{
TR Golub, DK Slonim, P Tamayo, C Huard, M Gaasenbeek, JP Mesirov, H Coller, ML Loh, JR Downing, MA Caligiuri, et al.
Molecular classification of cancer: class discovery and class prediction by gene expression monitoring
Science, 286 (1999), pp. 531-537

Ultsch, A., Thrun, M.C., Hansen-Goos, O., Loetsch, J.: Identification of Molecular Fingerprints
in Human Heat Pain Thresholds by Use of an Interactive Mixture Model R Toolbox(AdaptGauss),
International Journal of Molecular Sciences, doi:10.3390/ijms161025897, 2015.
}
\author{
Aixiang Jiang
}
\keyword{EM}
\keyword{PS}
