% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PSstableSLwithWeights.R
\name{PSstableSLwithWeights}
\alias{PSstableSLwithWeights}
\title{Self learning binary classification with selected features and their weights}
\usage{
PSstableSLwithWeights(newdat, weights, classProbCut = 0.9,
  PShighGroup = "PShigh", PSlowGroup = "PSlow", breaks = 50,
  EMmaxRuns = 50, imputeNA = FALSE, byrow = TRUE,
  imputeValue = c("median", "mean"))
}
\arguments{
\item{newdat}{a input data matrix or data frame, columns for samples and rows for features}

\item{weights}{a numeric vector with selected features (as names of the vector) and their weights}

\item{classProbCut}{a numeric variable within (0,1), which is a cutoff of Empirical Bayesian probability, 
often used values are 0.8 and 0.9, default value is 0.9. Only one value is used for both groups, 
the samples that are not included in either group will be assigned as UNCLASS}

\item{PShighGroup}{a string to indicate group name with high PS score}

\item{PSlowGroup}{a string to indicate group name with low PS score}

\item{breaks}{a integer to indicate number of bins in histogram, default is 50}

\item{EMmaxRuns}{number of Iterations for EM searching; default=50}

\item{imputeNA}{a logic variable to indicate if NA imputation is needed, if it is TRUE, NA imputation is 
processed before any other steps, the default is FALSE}

\item{byrow}{a logic variable to indicate direction for imputation, default is TRUE, 
which will use the row data for imputation}

\item{imputeValue}{a character variable to indicate which value to be used to replace NA, default is "median", 
the median value of the chose direction with "byrow" data to be used}
}
\value{
A list with two items is returned: PS parameters for selected features, PS scores and classifications for the given samples.
\item{PS_pars}{a list of 3 items, the 1st item is a data frame with weights of each selected features for PS
 calculation, the 2nd item is a numeric vector containing PS mean and sd for two groups，the 3rd item is a data frame contains 
 group means for each group and mean of these two means for each feature based on stable classes}
\item{PS_test}{a data frame of PS score and classification with natural 0 cutoff}
}
\description{
This function is to calculate PS (Prediction Strength) scores and make binary classification calls 
for a testing data set without PS training object. This function involves a self learning 
process with weights + priors + EM + Bayes but no need to input a group ratio prior. However, we do need selected feature list
with the feature weights, and we use self learning method to estimate parameters of the two groups for each selected feature 
in order to calculate PS scores.
}
\details{
This function is trying to get reasonable PS based classification without training data set, but with 
selected features and their weights. The actual steps are as following:
1) assume that we have a pool for group ratio priors such as: seq(0.05, 0.95, by = 0.05), this will give us 19 ratio priors
2) for each prior in 1), call PSSLwithWeightsPrior to achieve PS scores
3) apply EM on PS scores from 2) with Mclust, which includes 2 group classification
4) use the samples that are always in the same groups to get group means for each group and mean of these two means for each feature 
5) calculate PS scores
6) Once we have PS scores, we use the theoretic natual cutoff 0 to make classification calls
}
\references{
Golub TR, Slonim DK, Tamayo P, Huard C, Gaasenbeek M, Mesirov JP, et al. Molecular classification of cancer: 
class discovery and class prediction by gene expression monitoring. Science. 1999;286:531–7

Ultsch, A., Thrun, M.C., Hansen-Goos, O., Loetsch, J.: Identification of Molecular Fingerprints
in Human Heat Pain Thresholds by Use of an Interactive Mixture Model R Toolbox(AdaptGauss),
International Journal of Molecular Sciences, doi:10.3390/ijms161025897, 2015.

Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5: clustering, classification and 
density estimation using Gaussian finite mixture models, The R Journal, 8/1, pp. 205-233.
}
\author{
Aixiang Jiang
}
\keyword{EM}
\keyword{PS}
\keyword{self-learning}
