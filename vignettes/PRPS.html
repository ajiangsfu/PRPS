<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">



<title>Package PRPS</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' || rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">Package PRPS</h1>



<p>Type: Package</p>
<p>Title: Calculate classification scores and classify samples into 2 to 3 groups</p>
<p>Version: 0.1.0</p>
<p>Author: Aixiang Jiang, …, David Scott, Ryan Morin</p>
<p>Maintainer: Aixiang Jiang <a href="mailto:aijiang@bccrc.ca">aijiang@bccrc.ca</a></p>
<p>Depends: R (&gt;= 3.3.1), lattice, caret, limma, e1071</p>
<p>Suggests: knitr</p>
<p>VignetteBuilder: knir</p>
<p>   </p>
<div id="i.-introduction" class="section level1">
<h1>I. Introduction</h1>
<p>This package calculates classification prediction score with three method choices:</p>
<div id="lps-linear-prediction-score" class="section level2">
<h2>1. LPS (Linear Prediction Score);</h2>
<p>In the classification step, if LPS is chosen, Empirical Bayes’ probabilities are calcualted and classification is based on cutoff on probabilities;</p>
<div id="references" class="section level4">
<h4>References:</h4>
<p>Wright G, Tan B, Rosenwald A, Hurt EH, Wiestner A, Staudt LM. A trait expression-based method to diagnose clinically distinct subgroups of diffuse large B cell lymphoma. Proc Natl Acad Sci U S A. 2003 Aug 19;100(17):9991-6.</p>
</div>
</div>
<div id="prps-probability-ratio-based-classification-predication-score" class="section level2">
<h2>2. PRPS (Probability ratio based classification predication score);</h2>
<p>if PRPS is chosen, two types of outputs are given: one is based on cutoff on Empirical Bayes’ probabilities, the other one is based on natural cutoff 0 on PRPS scores;</p>
<div id="references-1" class="section level4">
<h4>References:</h4>
<p>Ennishi D, Jiang A, Boyle M, Collinge B, Grande BM, Ben-Neriah S, Rushton C, Tang J, Thomas N, Slack GW, Farinha P, Takata K, Miyata-Takata T, Craig J, Mottok A, Meissner B, Saberi S, Bashashati A, Villa D, Savage KJ, Sehn LH, Kridel R, Mungall AJ, Marra MA, Shah SP, Steidl C, Connors JM, Gascoyne RD, Morin RD, Scott DW. Double-Hit Trait Expression Signature Defines a Distinct Subgroup of Germinal Center B-Cell-Like Diffuse Large B-Cell Lymphoma. J Clin Oncol. 2018 Dec 3:JCO1801583. doi: 10.1200/JCO.18.01583.</p>
</div>
</div>
<div id="ps-prediction-strength." class="section level2">
<h2>3. PS (Prediction Strength).</h2>
<p>when PS is selected, by default, classification is based on natural cutoff 0 on PS scores, however, a separate function can alos issues classification based on cutoff on Empirical Bayes’ probabilities when necessary.</p>
<div id="references-2" class="section level4">
<h4>References:</h4>
<p>TR Golub, DK Slonim, P Tamayo, C Huard, M Gaasenbeek, JP Mesirov, H Coller, ML Loh, JR Downing, MA Caligiuri, et al. Molecular classification of cancer: class discovery and class prediction by gene expression monitoring Science, 286 (1999), pp. 531-537</p>
<p>   </p>
</div>
</div>
</div>
<div id="ii.-typical-path-training-testing" class="section level1">
<h1>II. Typical path: training + testing</h1>
<div id="typical-workflow-when-training-and-testing-data-sets-are-comparable" class="section level2">
<h2>1. Typical workflow when training and testing data sets are comparable</h2>
<p>When training and testing data sets are comparable, the typical workflow is:</p>
<p>1). select the algorithm you would like to use, there are three choices: LPS, PRPS, and PS</p>
<p>2). have your training data set ready, and make your decisions on the parameters</p>
<p>3). run LPStraining, or PRPStraining or PStraining</p>
<p>4). run LPStesting, or PRPStesting or PStesting</p>
</div>
<div id="example-data" class="section level2">
<h2>2. Example data</h2>
<p>In the data folder, there are four data files.</p>
<div id="rosenwald.cli" class="section level3">
<h3>1). rosenwald.cli</h3>
<p>This data frame contains subset clinic information about rosenwald dataset, wihch is downloaded from LPS R package: <a href="https://cran.r-project.org/web/packages/LPS/LPS.pdf" class="uri">https://cran.r-project.org/web/packages/LPS/LPS.pdf</a>. The original rosenwald data set contains 240 Diffuse Large B-Cell Lymphomas samples (<a href="https://llmpp.nih.gov/DLBCL/" class="uri">https://llmpp.nih.gov/DLBCL/</a>), in this subset, however, 40 samples were randomly selected from the training set that are not in Type III sub-types, and 20 samples ere randomly selected from the validation set that are not in Type III sub-types, together there are 60 Diffuse Large B-Cell Lymphomas samples in rosenwald.cli. The column “set” indicates if a sample was in training or validation data set in the Rosenwald paper, column group is for COO (cell of origin) classification, which could be GCB (germinal center), ABC (activated B cell) , and UNC (un-classified) in the paper, however, in this subset data, we only have GCB and ABC types.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PRPS)
<span class="kw">data</span>(<span class="st">&quot;rosenwald.cli&quot;</span>)
<span class="kw">str</span>(rosenwald.cli)
<span class="co">#&gt; 'data.frame':    60 obs. of  4 variables:</span>
<span class="co">#&gt;  $ set      : Factor w/ 2 levels &quot;Training&quot;,&quot;Validation&quot;: 1 1 1 1 1 1 1 1 1 1 ...</span>
<span class="co">#&gt;  $ group    : Factor w/ 2 levels &quot;ABC&quot;,&quot;GCB&quot;: 2 1 1 2 2 2 1 2 1 1 ...</span>
<span class="co">#&gt;  $ follow.up: num  2.4 1 10.5 1 1.6 0.2 10.8 2.3 8.4 1 ...</span>
<span class="co">#&gt;  $ status   : Factor w/ 2 levels &quot;Alive&quot;,&quot;Dead&quot;: 2 2 1 2 2 2 1 2 1 2 ...</span></code></pre></div>
<div id="references-3" class="section level4">
<h4>References:</h4>
<p>Rosenwald A, Wright G, Chan WC, et al. The use of molecular profiling to predict survival after chemotherapy for diffuse large-B-cell lymphoma. N Engl J Med 2002;346(25):1937-1947</p>
</div>
</div>
<div id="rosenwald.expr" class="section level3">
<h3>2). rosenwald.expr</h3>
<p>This data matrix contains Lymphochip microarrays expression data for the 60 Diffuse Large B-Cell Lymphomas samples as described in rosenwald.cli.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;rosenwald.expr&quot;</span>)
<span class="kw">str</span>(rosenwald.expr)
<span class="co">#&gt;  num [1:7399, 1:60] 0.607 0.239 0.828 0.932 0.86 0 0.476 0.814 0.81 0.87 ...</span>
<span class="co">#&gt;  - attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   ..$ : chr [1:7399] &quot;27481&quot; &quot;17013&quot; &quot;24751&quot; &quot;27498&quot; ...</span>
<span class="co">#&gt;   ..$ : chr [1:60] &quot;LYM018&quot; &quot;LYM120&quot; &quot;LYM180&quot; &quot;LYM285&quot; ...</span></code></pre></div>
<div id="references-4" class="section level4">
<h4>References:</h4>
<p>Rosenwald A, Wright G, Chan WC, et al. The use of molecular profiling to predict survival after chemotherapy for diffuse large-B-cell lymphoma. N Engl J Med 2002;346(25):1937-1947</p>
</div>
</div>
<div id="wrightcoo" class="section level3">
<h3>3). WrightCOO</h3>
<p>This data frame contains 158 COO (cell of origin) related genes with both Ensembl annotation ID (row names) and gene symbols (column “Gene”). These genes are used to classfy DLBCL samples into GCB, ABC, or UNC.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;WrightCOO&quot;</span>)
<span class="kw">str</span>(WrightCOO)
<span class="co">#&gt; 'data.frame':    158 obs. of  1 variable:</span>
<span class="co">#&gt;  $ Gene: chr  &quot;NR3C1&quot; &quot;PMM2&quot; &quot;STS&quot; &quot;BCL2&quot; ...</span>
<span class="kw">head</span>(WrightCOO)
<span class="co">#&gt;                  Gene</span>
<span class="co">#&gt; ENSG00000113580 NR3C1</span>
<span class="co">#&gt; ENSG00000140650  PMM2</span>
<span class="co">#&gt; ENSG00000101846   STS</span>
<span class="co">#&gt; ENSG00000171791  BCL2</span>
<span class="co">#&gt; ENSG00000168811 IL12A</span>
<span class="co">#&gt; ENSG00000196549   MME</span></code></pre></div>
<div id="references-5" class="section level4">
<h4>References:</h4>
<p>Wright G, Tan B, Rosenwald A, Hurt EH, Wiestner A, Staudt LM. A trait expression-based method to diagnose clinically distinct subgroups of diffuse large B cell lymphoma. Proc Natl Acad Sci U S A. 2003 Aug 19;100(17):9991-6.</p>
</div>
</div>
<div id="dhitsig" class="section level3">
<h3>4). DHITsig</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;DHITsig&quot;</span>)
<span class="kw">str</span>(DHITsig)
<span class="co">#&gt;  Named num [1:104] 0.674 0.666 0.618 0.597 0.582 ...</span>
<span class="co">#&gt;  - attr(*, &quot;names&quot;)= chr [1:104] &quot;OR13A1&quot; &quot;FAM216A&quot; &quot;MYC&quot; &quot;SLC25A27&quot; ...</span>
<span class="kw">head</span>(DHITsig)
<span class="co">#&gt;    OR13A1   FAM216A       MYC  SLC25A27     ALOX5     UQCRH </span>
<span class="co">#&gt; 0.6742184 0.6662736 0.6180968 0.5973289 0.5822841 0.5545504</span></code></pre></div>
<div id="references-6" class="section level4">
<h4>References:</h4>
<p>Ennishi D, Jiang A, Boyle M, Collinge B, Grande BM, Ben-Neriah S, Rushton C, Tang J, Thomas N, Slack GW, Farinha P, Takata K, Miyata-Takata T, Craig J, Mottok A, Meissner B, Saberi S, Bashashati A, Villa D, Savage KJ, Sehn LH, Kridel R, Mungall AJ, Marra MA, Shah SP, Steidl C, Connors JM, Gascoyne RD, Morin RD, Scott DW. Double-Hit Trait Expression Signature Defines a Distinct Subgroup of Germinal Center B-Cell-Like Diffuse Large B-Cell Lymphoma. J Clin Oncol. 2018 Dec 3:JCO1801583. doi: 10.1200/JCO.18.01583.</p>
</div>
</div>
</div>
<div id="example-code" class="section level2">
<h2>3. Example code</h2>
<p>In this section, we are providing example code to get classification score when training and testing data are comparable</p>
<div id="lps" class="section level3">
<h3>1) LPS</h3>
<div id="lpstraining" class="section level4">
<h4>LPStraining</h4>
<p>Get the data ready:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat =<span class="st"> </span>rosenwald.expr
trainset =<span class="st"> </span><span class="kw">subset</span>(rosenwald.cli, rosenwald.cli$set ==<span class="st"> &quot;Training&quot;</span>)
testset =<span class="st"> </span><span class="kw">subset</span>(rosenwald.cli, rosenwald.cli$set ==<span class="st"> &quot;Validation&quot;</span>)</code></pre></div>
<p>Use GCB as a reference group as in LPS package, then LPStraining result can be got as following</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nin =<span class="st"> </span><span class="dv">100</span> 
trainLPS =<span class="st"> </span><span class="kw">LPStraining</span> (<span class="dt">trainDat =</span> dat[,<span class="kw">rownames</span>(trainset)], <span class="dt">groupInfo =</span> trainset$group, <span class="dt">refGroup =</span> <span class="st">&quot;GCB&quot;</span>, <span class="dt">topN =</span> nin,
                      <span class="dt">weightMethod =</span> <span class="st">&quot;ttest&quot;</span>)
<span class="kw">str</span>(trainLPS)
<span class="co">#&gt; List of 4</span>
<span class="co">#&gt;  $ LPS_pars    :List of 2</span>
<span class="co">#&gt;   ..$ weights:'data.frame':  100 obs. of  3 variables:</span>
<span class="co">#&gt;   .. ..$ tValue: num [1:100] 7.94 7.43 7.14 6.86 6.79 ...</span>
<span class="co">#&gt;   .. ..$ pValue: num [1:100] 1.66e-09 6.59e-09 1.59e-08 4.85e-08 6.07e-08 ...</span>
<span class="co">#&gt;   .. ..$ FDR   : num [1:100] 1.23e-05 2.44e-05 3.93e-05 8.98e-05 8.98e-05 ...</span>
<span class="co">#&gt;   ..$ meansds: Named num [1:4] 373 -321 120 157</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;testLPSmean&quot; &quot;refLPSmean&quot; &quot;testLPSsd&quot; &quot;refLPSsd&quot;</span>
<span class="co">#&gt;  $ LPS_train   :'data.frame':    40 obs. of  5 variables:</span>
<span class="co">#&gt;   ..$ LPS_score    : num [1:40] -381.8 238.9 394.9 20.9 -306.2 ...</span>
<span class="co">#&gt;   ..$ true_class   : Factor w/ 2 levels &quot;ABC&quot;,&quot;GCB&quot;: 2 1 1 2 2 2 1 2 1 1 ...</span>
<span class="co">#&gt;   ..$ LPS_class    : chr [1:40] &quot;GCB&quot; &quot;ABC&quot; &quot;ABC&quot; &quot;UNCLASS&quot; ...</span>
<span class="co">#&gt;   ..$ LPS_prob_test: num [1:40] 3.42e-09 9.98e-01 1.00 1.58e-01 1.39e-07 ...</span>
<span class="co">#&gt;   ..$ LPS_prob_ref : num [1:40] 1.00 2.45e-03 2.36e-05 8.42e-01 1.00 ...</span>
<span class="co">#&gt;  $ classCompare:List of 6</span>
<span class="co">#&gt;   ..$ positive: chr &quot;ABC&quot;</span>
<span class="co">#&gt;   ..$ table   : 'table' int [1:2, 1:2] 22 0 0 16</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. .. ..$ Prediction: chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   .. .. ..$ Reference : chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   ..$ overall : Named num [1:7] 1 1 0.907 1 0.579 ...</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Accuracy&quot; &quot;Kappa&quot; &quot;AccuracyLower&quot; &quot;AccuracyUpper&quot; ...</span>
<span class="co">#&gt;   ..$ byClass : Named num [1:11] 1 1 1 1 1 ...</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;Sensitivity&quot; &quot;Specificity&quot; &quot;Pos Pred Value&quot; &quot;Neg Pred Value&quot; ...</span>
<span class="co">#&gt;   ..$ mode    : chr &quot;sens_spec&quot;</span>
<span class="co">#&gt;   ..$ dots    : list()</span>
<span class="co">#&gt;   ..- attr(*, &quot;class&quot;)= chr &quot;confusionMatrix&quot;</span>
<span class="co">#&gt;  $ classTable  : 'table' int [1:2, 1:3] 0 16 22 0 1 1</span>
<span class="co">#&gt;   ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. ..$ groupInfo: chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   .. ..$ LPS_class: chr [1:3] &quot;ABC&quot; &quot;GCB&quot; &quot;UNCLASS&quot;</span></code></pre></div>
<p>The last item in the output of LPStraining provides information on how our LPS prediction model is doing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trainLPS$classTable
<span class="co">#&gt;          LPS_class</span>
<span class="co">#&gt; groupInfo ABC GCB UNCLASS</span>
<span class="co">#&gt;       GCB   0  22       1</span>
<span class="co">#&gt;       ABC  16   0       1</span></code></pre></div>
<p>This means with given COO info, and with top 100 significant genes based on t test, LPS classification can put all GCB samples back to GCB samples, for ABC samples, however, one of them is put into UNCLASS, all other samples are put back into ABC.</p>
<p>More detail information about LPStraining function can be found with the two choices:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?(LPStraining)
<span class="kw">help</span>(LPStraining)
<span class="co">#&gt; Rendering development documentation for 'LPStraining'</span></code></pre></div>
</div>
<div id="lpstesting" class="section level4">
<h4>LPStesting</h4>
<p>Now, we need to have a testing data set that is comparable to the training data set. For this simple, however, we already have testing data set shown above, and we can use the output from LPStraining together with testing data set to do LPStesting, and compare the result from the original ABC-GCB classification.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testLPS =<span class="st"> </span><span class="kw">LPStesting</span>(<span class="dt">LPStrainObj =</span> trainLPS, <span class="dt">newdat =</span> dat[,<span class="kw">rownames</span>(testset)])
<span class="kw">str</span>(testLPS)
<span class="co">#&gt; 'data.frame':    20 obs. of  4 variables:</span>
<span class="co">#&gt;  $ LPS_score    : num  -81.3 -99.7 -217.2 215.3 358.5 ...</span>
<span class="co">#&gt;  $ LPS_class    : chr  &quot;GCB&quot; &quot;GCB&quot; &quot;GCB&quot; &quot;ABC&quot; ...</span>
<span class="co">#&gt;  $ LPS_prob_test: num  3.19e-03 1.48e-03 8.81e-06 9.95e-01 1.00 ...</span>
<span class="co">#&gt;  $ LPS_prob_ref : num  9.97e-01 9.99e-01 1.00 5.25e-03 6.55e-05 ...</span>
<span class="kw">table</span>(testLPS$LPS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt;     ABC     GCB UNCLASS </span>
<span class="co">#&gt;       6      13       1</span>
<span class="kw">table</span>(testLPS$LPS_class, testset$group)
<span class="co">#&gt;          </span>
<span class="co">#&gt;           ABC GCB</span>
<span class="co">#&gt;   ABC       6   0</span>
<span class="co">#&gt;   GCB       0  13</span>
<span class="co">#&gt;   UNCLASS   0   1</span></code></pre></div>
<p>We can also combine training and testing data sets together for testing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fullLPS =<span class="st"> </span><span class="kw">LPStesting</span>(<span class="dt">LPStrainObj =</span> trainLPS, <span class="dt">newdat =</span> dat)
<span class="kw">str</span>(fullLPS)
<span class="co">#&gt; 'data.frame':    60 obs. of  4 variables:</span>
<span class="co">#&gt;  $ LPS_score    : num  -381.8 238.9 394.9 20.9 -306.2 ...</span>
<span class="co">#&gt;  $ LPS_class    : chr  &quot;GCB&quot; &quot;ABC&quot; &quot;ABC&quot; &quot;UNCLASS&quot; ...</span>
<span class="co">#&gt;  $ LPS_prob_test: num  3.42e-09 9.98e-01 1.00 1.58e-01 1.39e-07 ...</span>
<span class="co">#&gt;  $ LPS_prob_ref : num  1.00 2.45e-03 2.36e-05 8.42e-01 1.00 ...</span>
<span class="kw">table</span>(fullLPS$LPS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt;     ABC     GCB UNCLASS </span>
<span class="co">#&gt;      22      35       3</span></code></pre></div>
<p>Now, we are wondering if the testLPS and fulltest give us consistent results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(testLPS$LPS_class, fullLPS[<span class="kw">rownames</span>(testset), <span class="st">&quot;LPS_class&quot;</span>])
<span class="co">#&gt;          </span>
<span class="co">#&gt;           ABC GCB UNCLASS</span>
<span class="co">#&gt;   ABC       6   0       0</span>
<span class="co">#&gt;   GCB       0  13       0</span>
<span class="co">#&gt;   UNCLASS   0   0       1</span></code></pre></div>
<p>More detail about LPStesting can be found with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?(LPStesting)
<span class="kw">help</span>(LPStesting)
<span class="co">#&gt; Rendering development documentation for 'LPStesting'</span></code></pre></div>
</div>
</div>
<div id="prps" class="section level3">
<h3>2) PRPS</h3>
<div id="prpstraining" class="section level4">
<h4>PRPStraining</h4>
<p>Use the same training data set as above, and use GCB as a reference group as in LPS package, then PRPStraining result can be got as following. Notice that now we are calling PRPStraining but all setting is the same as for LPStraining</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nin =<span class="st"> </span><span class="dv">100</span> 
trainPRPS =<span class="st"> </span><span class="kw">PRPStraining</span> (<span class="dt">trainDat =</span> dat[,<span class="kw">rownames</span>(trainset)], <span class="dt">groupInfo =</span> trainset$group, <span class="dt">refGroup =</span> <span class="st">&quot;GCB&quot;</span>, <span class="dt">topN =</span> nin,
                      <span class="dt">weightMethod =</span> <span class="st">&quot;ttest&quot;</span>)
<span class="kw">str</span>(trainPRPS)
<span class="co">#&gt; List of 4</span>
<span class="co">#&gt;  $ PRPS_pars   :List of 3</span>
<span class="co">#&gt;   ..$ weights      :'data.frame':    100 obs. of  3 variables:</span>
<span class="co">#&gt;   .. ..$ tValue: num [1:100] 7.94 7.43 7.14 6.86 6.79 ...</span>
<span class="co">#&gt;   .. ..$ pValue: num [1:100] 1.66e-09 6.59e-09 1.59e-08 4.85e-08 6.07e-08 ...</span>
<span class="co">#&gt;   .. ..$ FDR   : num [1:100] 1.23e-05 2.44e-05 3.93e-05 8.98e-05 8.98e-05 ...</span>
<span class="co">#&gt;   ..$ meansds      : Named num [1:4] 113.6 -137.4 38 53.4</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;testPRPSmean&quot; &quot;refPRPSmean&quot; &quot;testPRPSsd&quot; &quot;refPRPSsd&quot;</span>
<span class="co">#&gt;   ..$ traitsmeansds: num [1:100, 1:4] 0.482 0.389 0.434 0.715 0.351 ...</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. .. ..$ : chr [1:100] &quot;17708&quot; &quot;27631&quot; &quot;24796&quot; &quot;26697&quot; ...</span>
<span class="co">#&gt;   .. .. ..$ : chr [1:4] &quot;testmean&quot; &quot;refmean&quot; &quot;testsd&quot; &quot;refsd&quot;</span>
<span class="co">#&gt;  $ PRPS_train  :'data.frame':    40 obs. of  6 variables:</span>
<span class="co">#&gt;   ..$ PRPS_score    : num [1:40] -139.9 81.3 154.3 -43.1 -128.4 ...</span>
<span class="co">#&gt;   ..$ true_class    : Factor w/ 2 levels &quot;ABC&quot;,&quot;GCB&quot;: 2 1 1 2 2 2 1 2 1 1 ...</span>
<span class="co">#&gt;   ..$ PRPS_class    : chr [1:40] &quot;GCB&quot; &quot;ABC&quot; &quot;ABC&quot; &quot;GCB&quot; ...</span>
<span class="co">#&gt;   ..$ PRPS_prob_test: num [1:40] 3.20e-10 1.00 1.00 1.38e-03 2.31e-09 ...</span>
<span class="co">#&gt;   ..$ PRPS_prob_ref : num [1:40] 1.00 2.30e-04 4.12e-07 9.99e-01 1.00 ...</span>
<span class="co">#&gt;   ..$ PRPS_class0   : chr [1:40] &quot;GCB&quot; &quot;ABC&quot; &quot;ABC&quot; &quot;GCB&quot; ...</span>
<span class="co">#&gt;  $ classCompare:List of 6</span>
<span class="co">#&gt;   ..$ positive: chr &quot;ABC&quot;</span>
<span class="co">#&gt;   ..$ table   : 'table' int [1:2, 1:2] 23 0 0 16</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. .. ..$ Prediction: chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   .. .. ..$ Reference : chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   ..$ overall : Named num [1:7] 1 1 0.91 1 0.59 ...</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Accuracy&quot; &quot;Kappa&quot; &quot;AccuracyLower&quot; &quot;AccuracyUpper&quot; ...</span>
<span class="co">#&gt;   ..$ byClass : Named num [1:11] 1 1 1 1 1 ...</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;Sensitivity&quot; &quot;Specificity&quot; &quot;Pos Pred Value&quot; &quot;Neg Pred Value&quot; ...</span>
<span class="co">#&gt;   ..$ mode    : chr &quot;sens_spec&quot;</span>
<span class="co">#&gt;   ..$ dots    : list()</span>
<span class="co">#&gt;   ..- attr(*, &quot;class&quot;)= chr &quot;confusionMatrix&quot;</span>
<span class="co">#&gt;  $ classTable  : 'table' int [1:2, 1:3] 0 16 23 0 0 1</span>
<span class="co">#&gt;   ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. ..$ groupInfo : chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   .. ..$ PRPS_class: chr [1:3] &quot;ABC&quot; &quot;GCB&quot; &quot;UNCLASS&quot;</span></code></pre></div>
<p>The last item in the output of PRPStraining provides information on how our PRPS prediction model is doing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trainPRPS$classTable
<span class="co">#&gt;          PRPS_class</span>
<span class="co">#&gt; groupInfo ABC GCB UNCLASS</span>
<span class="co">#&gt;       GCB   0  23       0</span>
<span class="co">#&gt;       ABC  16   0       1</span></code></pre></div>
<p>This means with given COO info, and with top 100 significant genes based on t test, PRPS classification is 100% matching to given COO.</p>
<p>More detail information about LPStraining function can be found with the two choices:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?(PRPStraining)
<span class="kw">help</span>(PRPStraining)
<span class="co">#&gt; Rendering development documentation for 'PRPStraining'</span></code></pre></div>
</div>
<div id="prpstesting" class="section level4">
<h4>PRPStesting</h4>
<p>With the exact same testing data set as above, use the output from PRPStraining, we can apply PRPStesting as following and compare the classification with the truth in the testing data info:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testPRPS =<span class="st"> </span><span class="kw">PRPStesting</span>(<span class="dt">PRPStrainObj =</span> trainPRPS, <span class="dt">newdat =</span> dat[,<span class="kw">rownames</span>(testset)])
<span class="kw">str</span>(testPRPS)
<span class="co">#&gt; 'data.frame':    20 obs. of  5 variables:</span>
<span class="co">#&gt;  $ PRPS_score    : num  -59 -47.6 -95.9 52.6 108 ...</span>
<span class="co">#&gt;  $ PRPS_class    : chr  &quot;GCB&quot; &quot;GCB&quot; &quot;GCB&quot; &quot;ABC&quot; ...</span>
<span class="co">#&gt;  $ PRPS_prob_test: num  1.40e-04 7.27e-04 4.97e-07 9.95e-01 1.00 ...</span>
<span class="co">#&gt;  $ PRPS_prob_ref : num  1.00 9.99e-01 1.00 4.56e-03 1.84e-05 ...</span>
<span class="co">#&gt;  $ PRPS_class0   : chr  &quot;GCB&quot; &quot;GCB&quot; &quot;GCB&quot; &quot;ABC&quot; ...</span>
<span class="kw">table</span>(testPRPS$PRPS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt;     ABC     GCB UNCLASS </span>
<span class="co">#&gt;       6      13       1</span>
<span class="kw">table</span>(testPRPS$PRPS_class, testset$group)
<span class="co">#&gt;          </span>
<span class="co">#&gt;           ABC GCB</span>
<span class="co">#&gt;   ABC       6   0</span>
<span class="co">#&gt;   GCB       0  13</span>
<span class="co">#&gt;   UNCLASS   0   1</span></code></pre></div>
<p>We can also combine training and testing data sets together for testing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fullPRPS =<span class="st"> </span><span class="kw">PRPStesting</span>(<span class="dt">PRPStrainObj =</span> trainPRPS, <span class="dt">newdat =</span> dat)
<span class="kw">str</span>(fullPRPS)
<span class="co">#&gt; 'data.frame':    60 obs. of  5 variables:</span>
<span class="co">#&gt;  $ PRPS_score    : num  -139.9 81.3 154.3 -43.1 -128.4 ...</span>
<span class="co">#&gt;  $ PRPS_class    : chr  &quot;GCB&quot; &quot;ABC&quot; &quot;ABC&quot; &quot;GCB&quot; ...</span>
<span class="co">#&gt;  $ PRPS_prob_test: num  3.20e-10 1.00 1.00 1.38e-03 2.31e-09 ...</span>
<span class="co">#&gt;  $ PRPS_prob_ref : num  1.00 2.30e-04 4.12e-07 9.99e-01 1.00 ...</span>
<span class="co">#&gt;  $ PRPS_class0   : chr  &quot;GCB&quot; &quot;ABC&quot; &quot;ABC&quot; &quot;GCB&quot; ...</span>
<span class="kw">table</span>(fullPRPS$PRPS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt;     ABC     GCB UNCLASS </span>
<span class="co">#&gt;      22      36       2</span></code></pre></div>
<p>Now, we are wondering if the testLPS and fulltest give us consistent results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(testPRPS$PRPS_class, fullPRPS[<span class="kw">rownames</span>(testset), <span class="st">&quot;PRPS_class&quot;</span>])
<span class="co">#&gt;          </span>
<span class="co">#&gt;           ABC GCB UNCLASS</span>
<span class="co">#&gt;   ABC       6   0       0</span>
<span class="co">#&gt;   GCB       0  13       0</span>
<span class="co">#&gt;   UNCLASS   0   0       1</span></code></pre></div>
<p>If we compare PRPS results with LPS results, we can find that the training data itself is 100% matched to the truth for LPS but there is one sample put into UNCLASS based on PRPS. However, for the testing data set, there is one GCB sample was classified to ABC by LPS, while ihe same samppe is classified into UNCLASS by PRPS, which seems more reasonable.</p>
</div>
</div>
<div id="ps" class="section level3">
<h3>3) PS</h3>
<div id="pstraining" class="section level4">
<h4>PStraining</h4>
<p>Use the same training data set as above, and use GCB as a reference group as in LPS package, then PStraining result can be got as following. Notice that now we are calling PStraining but all setting is the same as for LPStraining</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nin =<span class="st"> </span><span class="dv">100</span> 
trainPS =<span class="st"> </span><span class="kw">PStraining</span> (<span class="dt">trainDat =</span> dat[,<span class="kw">rownames</span>(trainset)], <span class="dt">groupInfo =</span> trainset$group, <span class="dt">refGroup =</span> <span class="st">&quot;GCB&quot;</span>, <span class="dt">topN =</span> nin, <span class="dt">weightMethod =</span> <span class="st">&quot;ttest&quot;</span>)
<span class="kw">str</span>(trainPS)
<span class="co">#&gt; List of 4</span>
<span class="co">#&gt;  $ PS_pars     :'data.frame':    100 obs. of  6 variables:</span>
<span class="co">#&gt;   ..$ meanOfGroupMeans: num [1:100] 0.0999 0.1135 0.1108 0.1107 0.0928 ...</span>
<span class="co">#&gt;   ..$ tValue          : num [1:100] 7.94 7.43 7.14 6.86 6.79 ...</span>
<span class="co">#&gt;   ..$ refGroupMean    : num [1:100] -0.679 -0.643 -0.628 -0.627 -0.631 ...</span>
<span class="co">#&gt;   ..$ testGroupMean   : num [1:100] 0.879 0.87 0.849 0.849 0.816 ...</span>
<span class="co">#&gt;   ..$ pValue          : num [1:100] 1.66e-09 6.59e-09 1.59e-08 4.85e-08 6.07e-08 ...</span>
<span class="co">#&gt;   ..$ FDR             : num [1:100] 1.23e-05 2.44e-05 3.93e-05 8.98e-05 8.98e-05 ...</span>
<span class="co">#&gt;  $ PS_train    :'data.frame':    40 obs. of  3 variables:</span>
<span class="co">#&gt;   ..$ PS_score  : num [1:40] -0.783 0.53 0.866 -0.27 -0.727 ...</span>
<span class="co">#&gt;   ..$ true_class: Factor w/ 2 levels &quot;ABC&quot;,&quot;GCB&quot;: 2 1 1 2 2 2 1 2 1 1 ...</span>
<span class="co">#&gt;   ..$ PS_class  : chr [1:40] &quot;GCB&quot; &quot;ABC&quot; &quot;ABC&quot; &quot;GCB&quot; ...</span>
<span class="co">#&gt;  $ classCompare:List of 6</span>
<span class="co">#&gt;   ..$ positive: chr &quot;ABC&quot;</span>
<span class="co">#&gt;   ..$ table   : 'table' int [1:2, 1:2] 23 0 0 17</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. .. ..$ Prediction: chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   .. .. ..$ Reference : chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   ..$ overall : Named num [1:7] 1 1 0.912 1 0.575 ...</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Accuracy&quot; &quot;Kappa&quot; &quot;AccuracyLower&quot; &quot;AccuracyUpper&quot; ...</span>
<span class="co">#&gt;   ..$ byClass : Named num [1:11] 1 1 1 1 1 1 1 0.425 0.425 0.425 ...</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;Sensitivity&quot; &quot;Specificity&quot; &quot;Pos Pred Value&quot; &quot;Neg Pred Value&quot; ...</span>
<span class="co">#&gt;   ..$ mode    : chr &quot;sens_spec&quot;</span>
<span class="co">#&gt;   ..$ dots    : list()</span>
<span class="co">#&gt;   ..- attr(*, &quot;class&quot;)= chr &quot;confusionMatrix&quot;</span>
<span class="co">#&gt;  $ classTable  : 'table' int [1:2, 1:2] 23 0 0 17</span>
<span class="co">#&gt;   ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. ..$ groupInfo: chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   .. ..$ PS_class : chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span></code></pre></div>
<p>The last item in the output of PStraining provides information on how our PS prediction model is doing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trainPS$classTable
<span class="co">#&gt;          PS_class</span>
<span class="co">#&gt; groupInfo GCB ABC</span>
<span class="co">#&gt;       GCB  23   0</span>
<span class="co">#&gt;       ABC   0  17</span></code></pre></div>
<p>This means with given COO info, and with top 100 significant genes based on t test, PS classification is 100% matching to given COO.</p>
<p>More detail information about LPStraining function can be found with the two choices:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?(PStraining)
<span class="kw">help</span>(PStraining)
<span class="co">#&gt; Rendering development documentation for 'PStraining'</span></code></pre></div>
</div>
<div id="pstesting" class="section level4">
<h4>PStesting</h4>
<p>With the exact same testing data set as above, use the output from PStraining, we can apply PStesting as following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testPS =<span class="st"> </span><span class="kw">PStesting</span>(<span class="dt">PStrainObj =</span> trainPS, <span class="dt">newdat =</span> dat[,<span class="kw">rownames</span>(testset)])
<span class="kw">str</span>(testPS)
<span class="co">#&gt; 'data.frame':    20 obs. of  2 variables:</span>
<span class="co">#&gt;  $ PS_score: num  -0.23 -0.367 -0.669 0.609 0.788 ...</span>
<span class="co">#&gt;  $ PS_class: chr  &quot;GCB&quot; &quot;GCB&quot; &quot;GCB&quot; &quot;ABC&quot; ...</span>
<span class="kw">table</span>(testPS$PS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt; ABC GCB </span>
<span class="co">#&gt;   7  13</span>
<span class="kw">table</span>(testPS$PS_class, testset$group)
<span class="co">#&gt;      </span>
<span class="co">#&gt;       ABC GCB</span>
<span class="co">#&gt;   ABC   6   1</span>
<span class="co">#&gt;   GCB   0  13</span></code></pre></div>
<p>We can also combine training and testing data sets together for testing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fullPS =<span class="st"> </span><span class="kw">PStesting</span>(<span class="dt">PStrainObj =</span> trainPS, <span class="dt">newdat =</span> dat)
<span class="kw">str</span>(fullPS)
<span class="co">#&gt; 'data.frame':    60 obs. of  2 variables:</span>
<span class="co">#&gt;  $ PS_score: num  -0.781 0.51 0.883 -0.224 -0.701 ...</span>
<span class="co">#&gt;  $ PS_class: chr  &quot;GCB&quot; &quot;ABC&quot; &quot;ABC&quot; &quot;GCB&quot; ...</span>
<span class="kw">table</span>(fullPS$PS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt; ABC GCB </span>
<span class="co">#&gt;  24  36</span></code></pre></div>
<p>Now, we are wondering if the testLPS and fulltest give us consistent results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(testPS$PS_class, fullPS[<span class="kw">rownames</span>(testset), <span class="st">&quot;PS_class&quot;</span>])
<span class="co">#&gt;      </span>
<span class="co">#&gt;       ABC GCB</span>
<span class="co">#&gt;   ABC   7   0</span>
<span class="co">#&gt;   GCB   0  13</span></code></pre></div>
<p>PS performs exactly the same as LPS for the above training and testing data sets.</p>
<p>   </p>
</div>
</div>
</div>
</div>
<div id="iii.-special-path-classification-score-calculation-without-comparable-training" class="section level1">
<h1>III. Special path: classification score calculation without comparable training</h1>
<p>In many situations, we might not have comparable training and testing data sets, in this case, we might still calculate classification scores and make classification calls.</p>
<div id="a-similar-data-set-with-classificaiton-info-is-available" class="section level2">
<h2>1. A similar data set with classificaiton info is available</h2>
<p>If there is no comparable training data available, but there is a similar to testing data with classification info available, we might apply calibration or normalization or standardization to make it as our pseudo training data set. In this case, we can do the following:</p>
<ol style="list-style-type: lower-roman">
<li><p>If we believe that there is only some score shifting between training and testing data sets, calibrate classification scores between testing and traning data sets, and then use the calibrated mean and sd of two groups in the traning data set to calculate Empirical Bayes probabilities for the testing data set, and furthermore get classification calls. Notice that this approach is easy for LPS method but not easy for PROS and PS. This is because PRPS and PS require feature level group info as well, which is more difficult to deal with.</p></li>
<li><p>If the assumption in i) does not hold, which means that there are more difference between training and testing data sets, and calibration on classification scores cannot overcome the difference, but if we have house keeping genes, we can use house keeping genes to normalize both training and testing data sets, and use the normalized training and testing data sets and follow instruction in II Typical path: training + testing. This normalization strategy can be applied for all three algorithm in this package: LPS, PRPS and PS. The assumption, however, is that these house keeping genes perform similar across training and testing data sets. When this assumption does not hold, this approach will not work.</p></li>
<li><p>If both i) and ii) are not applicable, which means that the calibration on classification scores does not work and we cannot use house keeping genes for normalization, then, we can apply feature-wise standardization for both pseudo training and testing data sets. In this case, when we follow instruction in II Typical path: training + testing, we just need to make sure standardization = TRUE. This approach can be worked for all three algorithms in this package: LPS, PRPS and PS. The assumption is, however, the ture distribution for each feature is similar between training and testing data sets. If not, this approach will not work. For example, if there is a significant higher proportion of one group in the testing data set than in the training data set, normalization method will not work.</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lpstrain =<span class="st"> </span><span class="kw">LPStraining</span> (<span class="dt">trainDat =</span> dat[,<span class="kw">rownames</span>(trainset)], <span class="dt">standardization=</span><span class="ot">TRUE</span>, <span class="dt">groupInfo =</span> trainset$group, <span class="dt">refGroup =</span> <span class="st">&quot;GCB&quot;</span>, <span class="dt">topN =</span> nin,<span class="dt">weightMethod =</span> <span class="st">&quot;ttest&quot;</span>)
<span class="kw">str</span>(trainLPS)
<span class="co">#&gt; List of 4</span>
<span class="co">#&gt;  $ LPS_pars    :List of 2</span>
<span class="co">#&gt;   ..$ weights:'data.frame':  100 obs. of  3 variables:</span>
<span class="co">#&gt;   .. ..$ tValue: num [1:100] 7.94 7.43 7.14 6.86 6.79 ...</span>
<span class="co">#&gt;   .. ..$ pValue: num [1:100] 1.66e-09 6.59e-09 1.59e-08 4.85e-08 6.07e-08 ...</span>
<span class="co">#&gt;   .. ..$ FDR   : num [1:100] 1.23e-05 2.44e-05 3.93e-05 8.98e-05 8.98e-05 ...</span>
<span class="co">#&gt;   ..$ meansds: Named num [1:4] 373 -321 120 157</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;testLPSmean&quot; &quot;refLPSmean&quot; &quot;testLPSsd&quot; &quot;refLPSsd&quot;</span>
<span class="co">#&gt;  $ LPS_train   :'data.frame':    40 obs. of  5 variables:</span>
<span class="co">#&gt;   ..$ LPS_score    : num [1:40] -381.8 238.9 394.9 20.9 -306.2 ...</span>
<span class="co">#&gt;   ..$ true_class   : Factor w/ 2 levels &quot;ABC&quot;,&quot;GCB&quot;: 2 1 1 2 2 2 1 2 1 1 ...</span>
<span class="co">#&gt;   ..$ LPS_class    : chr [1:40] &quot;GCB&quot; &quot;ABC&quot; &quot;ABC&quot; &quot;UNCLASS&quot; ...</span>
<span class="co">#&gt;   ..$ LPS_prob_test: num [1:40] 3.42e-09 9.98e-01 1.00 1.58e-01 1.39e-07 ...</span>
<span class="co">#&gt;   ..$ LPS_prob_ref : num [1:40] 1.00 2.45e-03 2.36e-05 8.42e-01 1.00 ...</span>
<span class="co">#&gt;  $ classCompare:List of 6</span>
<span class="co">#&gt;   ..$ positive: chr &quot;ABC&quot;</span>
<span class="co">#&gt;   ..$ table   : 'table' int [1:2, 1:2] 22 0 0 16</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. .. ..$ Prediction: chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   .. .. ..$ Reference : chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   ..$ overall : Named num [1:7] 1 1 0.907 1 0.579 ...</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Accuracy&quot; &quot;Kappa&quot; &quot;AccuracyLower&quot; &quot;AccuracyUpper&quot; ...</span>
<span class="co">#&gt;   ..$ byClass : Named num [1:11] 1 1 1 1 1 ...</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;Sensitivity&quot; &quot;Specificity&quot; &quot;Pos Pred Value&quot; &quot;Neg Pred Value&quot; ...</span>
<span class="co">#&gt;   ..$ mode    : chr &quot;sens_spec&quot;</span>
<span class="co">#&gt;   ..$ dots    : list()</span>
<span class="co">#&gt;   ..- attr(*, &quot;class&quot;)= chr &quot;confusionMatrix&quot;</span>
<span class="co">#&gt;  $ classTable  : 'table' int [1:2, 1:3] 0 16 22 0 1 1</span>
<span class="co">#&gt;   ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. ..$ groupInfo: chr [1:2] &quot;GCB&quot; &quot;ABC&quot;</span>
<span class="co">#&gt;   .. ..$ LPS_class: chr [1:3] &quot;ABC&quot; &quot;GCB&quot; &quot;UNCLASS&quot;</span>

lpstest =<span class="st"> </span><span class="kw">LPStesting</span>(lpstrain, <span class="dt">newdat =</span> dat[,<span class="kw">rownames</span>(testset)], <span class="dt">standardization =</span> <span class="ot">TRUE</span>)
<span class="kw">str</span>(lpstest)
<span class="co">#&gt; 'data.frame':    20 obs. of  4 variables:</span>
<span class="co">#&gt;  $ LPS_score    : num  -35 -126 -218 218 366 ...</span>
<span class="co">#&gt;  $ LPS_class    : chr  &quot;GCB&quot; &quot;GCB&quot; &quot;GCB&quot; &quot;ABC&quot; ...</span>
<span class="co">#&gt;  $ LPS_prob_test: num  9.22e-03 1.93e-04 3.02e-06 9.94e-01 1.00 ...</span>
<span class="co">#&gt;  $ LPS_prob_ref : num  9.91e-01 1.00 1.00 6.27e-03 4.29e-05 ...</span></code></pre></div>
<p>In general, this is not a big problem is there is linear shift in classification score level, or even in feature level. But we do have problem to deal with data if distribution is different between training and testing.</p>
</div>
<div id="no-similar-data-set-with-classificaiton-info-is-available" class="section level2">
<h2>2. No similar data set with classificaiton info is available</h2>
<p>Not only we do not have comparable training and testing data sets, but also we do not have similar training and testing data sets. This means that we do not have any kinds of training data sets at all. In this situation, we should at least have gene features/traits that we would like to distiguish samples. Otherwise no classification score can be calculated.</p>
<div id="weights-for-selected-featurestraits-are-available" class="section level3">
<h3>1). Weights for selected features/traits are available</h3>
<p>If we know selected features/traits with their weights but no any kind of training data set, and we would like to calculate classification score for a given tesing data set, what can we do?</p>
<div id="lps-1" class="section level4">
<h4>LPS</h4>
<p>Without any further information and without any assumption, the only method we can use to calculate classification score is to apply LPS approach. In this case, we can call getClassScores and set method as LPS.</p>
<p>Assuming that we have features and their weights from some where, for example, we can get this information from trainLPS:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lpswts =<span class="st"> </span>trainLPS$LPS_pars$weights
<span class="kw">str</span>(lpswts)
<span class="co">#&gt; 'data.frame':    100 obs. of  3 variables:</span>
<span class="co">#&gt;  $ tValue: num  7.94 7.43 7.14 6.86 6.79 ...</span>
<span class="co">#&gt;  $ pValue: num  1.66e-09 6.59e-09 1.59e-08 4.85e-08 6.07e-08 ...</span>
<span class="co">#&gt;  $ FDR   : num  1.23e-05 2.44e-05 3.93e-05 8.98e-05 8.98e-05 ...</span></code></pre></div>
<p>Here, the tValue is the weight for the top 100 genes selected with LPStraining.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">genes =<span class="st"> </span><span class="kw">rownames</span>(lpswts)
lpswts =<span class="st"> </span>lpswts[,<span class="dv">1</span>]
<span class="kw">names</span>(lpswts) =<span class="st"> </span>genes
<span class="kw">head</span>(lpswts)
<span class="co">#&gt;     17708     27631     24796     26697     27562     17496 </span>
<span class="co">#&gt;  7.938396  7.431466  7.144285  6.859320  6.793850 -6.606511</span></code></pre></div>
<p>With the same <em>testdat</em>, we can get LPS score with function: getClassScores</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lpsscores =<span class="st"> </span><span class="kw">getClassScores</span>(<span class="dt">testdat =</span> dat[,<span class="kw">rownames</span>(testset)], <span class="dt">classMethod =</span> <span class="st">&quot;LPS&quot;</span>, <span class="dt">weights =</span> lpswts)
<span class="kw">head</span>(lpsscores)
<span class="co">#&gt;     LYM137     LYM142     LYM112     LYM005     LYM064     LYM089 </span>
<span class="co">#&gt;  -81.28411  -99.71485 -217.24959  215.32058  358.50245  420.65129</span></code></pre></div>
<p>While LPS score calculation only requires weights, in order to get classification, we need more information to help us. LPS classification is based on Empirical Bayes probabilities, which requires LPS score mean and sd for two groups (for the example data, GCB or ABC). In order to get these information, we might use the following methods to make classifcation calls:</p>
<ol style="list-style-type: lower-roman">
<li><p>Assume a prior that indicate what percentage of scores can be used to calculate group mean and sd for both groups, obviously but by median is the most conservative way to do so, you migt try 1/3 for one group and 2/3 for the other group, or 1/3 in both ends.</p></li>
<li><p>Visualize the score distribution with histogram or any other tools, and get the initial classification, then calculate score mean and sd for both groups.</p></li>
</ol>
<p>Once we have LPS scores with i) or ii), and LPS score mean and sd for the two groups, we can calcualte Empirical Bayes probabilities, and make classification calls as usual.</p>
</div>
<div id="prps-and-ps" class="section level4">
<h4>PRPS and PS</h4>
<p>When PRPS and PS methods are chosen, we need to use initial group information to calculate PRPS and PS classification scores. Again, both prior and visualization methods can be used as for LPS appraoch. The differene is that we need this info to calculate mean and sd for the two groups for each gene level in order to get PRPS and PS scores. Again, we need to call getClassScores function:</p>
<p>getClassScores(testdat, classMethod = c(“LPS”, “PRPS”, “PS”), weights, classMeans, classSds)</p>
<p>When we have these classification scores, and if we do not want to use natual cutoff of 0 to claim classification, but want to calculate Empirical Bayes probabilities, then, at the this point, we need to use initial group information again, and then make classification calls.</p>
</div>
</div>
<div id="weights-for-selected-featurestraits-are-not-available" class="section level3">
<h3>2). Weights for selected features/traits are NOT available</h3>
<div id="the-following-section-seesm-not-work-however-i-might-use-approach-for-dlc-gcb-coo-with-self-learning-and-extension-to-other-cases" class="section level4">
<h4>the following section seesm not work, however, I might use approach for DLC GCB COO with self learning and extension to other cases</h4>
<p>and more cohorts as example, here, we do not have training and testing, and we do not have COO weights, but we do have …, I am confused, think more later <!-- If we only know selected features/traits, but we do not know these features' weights, and we do not have any kinds of training data sets. In this case, we might do the following --></p>
<!-- i) Standardize data along each feature/trait, make all feature's distribution comparable to N(0,1) -->
<!-- ii) use equal weight of 1 for all selected features/traits -->
<!-- iii) follow all steps in 1). Weights for selected features/traits are available -->
<p>   </p>
</div>
</div>
</div>
</div>
<div id="iv-plots" class="section level1">
<h1>IV Plots</h1>
<p>For the training and testing objects, we can alos plot them out.</p>
<div id="plot-training-objects" class="section level2">
<h2>1. Plot training objects</h2>
<p>For all LPS and PRPS training objects, we can plot ROC curve, histogram, and Empirical Bayesian probabilites vs classification score scatter plot. For PS training objects, only ROC curve and histogram plots are produced because PS method does not involve Empirical Bayesian probability calculation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">plotNames =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;lpsPlots&quot;</span>,<span class="st">&quot;prpsPlots&quot;</span>,<span class="st">&quot;psPlots&quot;</span>)
trainNames =<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;train&quot;</span>,plotNames, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>)
<span class="kw">plotTraining</span>(<span class="dt">trainObj =</span> trainLPS, <span class="dt">plotName =</span> trainNames[<span class="dv">1</span>])
<span class="co">#&gt; png </span>
<span class="co">#&gt;   2</span>
<span class="kw">plotTraining</span>(<span class="dt">trainObj =</span> trainPRPS, <span class="dt">plotName =</span> trainNames[<span class="dv">2</span>])
<span class="co">#&gt; png </span>
<span class="co">#&gt;   2</span>
<span class="kw">plotTraining</span>(<span class="dt">trainObj =</span> trainPS, <span class="dt">plotName =</span> trainNames[<span class="dv">3</span>])
<span class="co">#&gt; png </span>
<span class="co">#&gt;   2</span></code></pre></div>
<p>The plot files are saved with given file names. Notice that the ROC curve usually ahould be 100% AUC, this is because classification scores from one given group should be always bigger or smaller than the other group. When the scores are overlapped in order, AUC will not 100% any more.</p>
</div>
<div id="plot-testing-objects" class="section level2">
<h2>2. Plot testing objects</h2>
<p>For all LPS and PRPS training objects, we can plot histogram and Empirical Bayesian probabilites vs classification score scatter plot. For PS training objects, only histogram plots are produced because PS method does not involve Empirical Bayesian probability calculation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testNames =<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;test&quot;</span>,plotNames, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>)
<span class="kw">plotTesting</span>(<span class="dt">testObj =</span> testLPS, <span class="dt">plotName =</span> testNames[<span class="dv">1</span>])
<span class="co">#&gt; png </span>
<span class="co">#&gt;   2</span>
<span class="kw">plotTesting</span>(<span class="dt">testObj =</span> testPRPS, <span class="dt">plotName =</span> testNames[<span class="dv">2</span>])
<span class="co">#&gt; png </span>
<span class="co">#&gt;   2</span>
<span class="kw">plotTesting</span>(<span class="dt">testObj =</span> testPS, <span class="dt">plotName =</span> testNames[<span class="dv">3</span>])
<span class="co">#&gt; png </span>
<span class="co">#&gt;   2</span></code></pre></div>
<p>The plot files are saved with given file names.</p>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
