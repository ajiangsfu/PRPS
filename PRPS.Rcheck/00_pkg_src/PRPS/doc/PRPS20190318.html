<!DOCTYPE html>
<!-- saved from url=(0104)http://thanos.mbb.sfu.ca:8787/file_show?path=%2Ftmp%2FRtmpW8l4Fs%2Fpreview-1c8d86cadb318.dir%2FPRPS.html -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">



<meta name="generator" content="pandoc">

<meta name="viewport" content="width=device-width, initial-scale=1">



<title>Package PRPS</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' || rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css">

<script type="text/javascript" src="./Package PRPS_files/MathJax.js.download"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>

<body><div id="MathJax_Message" style="display: none;"></div>




<h1 class="title toc-ignore">Package PRPS</h1>



<p>Type: Package</p>
<p>Title: Calculate classification scores and classify samples into 2 to 3 groups</p>
<p>Version: 0.1.0</p>
<p>Author: Aixiang Jiang, …, David Scott, Ryan Morin</p>
<p>Maintainer: Aixiang Jiang <a href="mailto:aijiang@bccrc.ca">aijiang@bccrc.ca</a></p>
<p>Depends: R (&gt;= 3.3.1), lattice, caret, limma, e1071</p>
<p>Suggests: knitr</p>
<p>VignetteBuilder: knir</p>
<p>&nbsp; &nbsp;</p>
<div id="i.-introduction" class="section level1">
<h1>I. Introduction</h1>
<p>This package calculates classification prediction score with three method choices:</p>
<div id="lps-linear-prediction-score" class="section level2">
<h2>1. LPS (Linear Prediction Score);</h2>
<p>In the classification step, if LPS is chosen, Empirical Bayes’ probabilities are calcualted and classification is based on cutoff on probabilities;</p>
<div id="references" class="section level4">
<h4>References:</h4>
<p>Wright G, Tan B, Rosenwald A, Hurt EH, Wiestner A, Staudt LM. A trait expression-based method to diagnose clinically distinct subgroups of diffuse large B cell lymphoma. Proc Natl Acad Sci U S A. 2003 Aug 19;100(17):9991-6.</p>
</div>
</div>
<div id="prps-probability-ratio-based-classification-predication-score" class="section level2">
<h2>2. PRPS (Probability ratio based classification predication score);</h2>
<p>if PRPS is chosen, two types of outputs are given: one is based on cutoff on Empirical Bayes’ probabilities, the other one is based on natural cutoff 0 on PRPS scores;</p>
<div id="references-1" class="section level4">
<h4>References:</h4>
<p>Ennishi D, Jiang A, Boyle M, Collinge B, Grande BM, Ben-Neriah S, Rushton C, Tang J, Thomas N, Slack GW, Farinha P, Takata K, Miyata-Takata T, Craig J, Mottok A, Meissner B, Saberi S, Bashashati A, Villa D, Savage KJ, Sehn LH, Kridel R, Mungall AJ, Marra MA, Shah SP, Steidl C, Connors JM, Gascoyne RD, Morin RD, Scott DW. Double-Hit Trait Expression Signature Defines a Distinct Subgroup of Germinal Center B-Cell-Like Diffuse Large B-Cell Lymphoma. J Clin Oncol. 2018 Dec 3:JCO1801583. doi: 10.1200/JCO.18.01583.</p>
</div>
</div>
<div id="ps-prediction-strength." class="section level2">
<h2>3. PS (Prediction Strength).</h2>
<p>when PS is selected, by default, classification is based on natural cutoff 0 on PS scores, however, a separate function can alos issues classification based on cutoff on Empirical Bayes’ probabilities when necessary.</p>
<div id="references-2" class="section level4">
<h4>References:</h4>
<p>TR Golub, DK Slonim, P Tamayo, C Huard, M Gaasenbeek, JP Mesirov, H Coller, ML Loh, JR Downing, MA Caligiuri, et al. Molecular classification of cancer: class discovery and class prediction by gene expression monitoring Science, 286 (1999), pp.&nbsp;531-537</p>
<p>&nbsp; &nbsp;</p>
</div>
</div>
</div>
<div id="ii.-typical-path-training-testing" class="section level1">
<h1>II. Typical path: training + testing</h1>
<div id="typical-workflow-when-training-and-testing-data-sets-are-comparable" class="section level2">
<h2>1. Typical workflow when training and testing data sets are comparable</h2>
<p>When training and testing data sets are comparable, the typical workflow is:</p>
<p>1). select the algorithm you would like to use, there are three choices: LPS, PRPS, and PS</p>
<p>2). have your training data set ready, and make your decisions on the parameters</p>
<p>3). run LPStraining, or PRPStraining or PStraining</p>
<p>4). run LPStesting, or PRPStesting or PStesting</p>
</div>
<div id="example-data" class="section level2">
<h2>2. Example data</h2>
<p>In the data folder, there are four data files.</p>
<div id="rosenwald.cli" class="section level3">
<h3>1). rosenwald.cli</h3>
<p>This data frame contains subset clinic information about rosenwald dataset, wihch is downloaded from LPS R package: <a href="https://cran.r-project.org/web/packages/LPS/LPS.pdf" class="uri">https://cran.r-project.org/web/packages/LPS/LPS.pdf</a>. The original rosenwald data set contains 240 Diffuse Large B-Cell Lymphomas samples (<a href="https://llmpp.nih.gov/DLBCL/" class="uri">https://llmpp.nih.gov/DLBCL/</a>), in this subset, however, 40 samples were randomly selected from the training set that are not in Type III sub-types, and 20 samples ere randomly selected from the validation set that are not in Type III sub-types, together there are 60 Diffuse Large B-Cell Lymphomas samples in rosenwald.cli. The column “set” indicates if a sample was in training or validation data set in the Rosenwald paper, column group is for COO (cell of origin) classification, which could be GCB (germinal center), ABC (activated B cell) , and UNC (un-classified) in the paper, however, in this subset data, we only have GCB and ABC types.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PRPS)
<span class="co">#&gt; Loading required package: lattice</span>
<span class="co">#&gt; Loading required package: caret</span>
<span class="co">#&gt; Loading required package: limma</span>
<span class="co">#&gt; Loading required package: e1071</span>
<span class="kw">data</span>(<span class="st">"rosenwald.cli"</span>)
<span class="kw">str</span>(rosenwald.cli)
<span class="co">#&gt; 'data.frame':    60 obs. of  4 variables:</span>
<span class="co">#&gt;  $ set      : Factor w/ 2 levels "Training","Validation": 1 1 1 1 1 1 1 1 1 1 ...</span>
<span class="co">#&gt;  $ group    : Factor w/ 2 levels "ABC","GCB": 2 1 1 2 2 2 1 2 1 1 ...</span>
<span class="co">#&gt;  $ follow.up: num  2.4 1 10.5 1 1.6 0.2 10.8 2.3 8.4 1 ...</span>
<span class="co">#&gt;  $ status   : Factor w/ 2 levels "Alive","Dead": 2 2 1 2 2 2 1 2 1 2 ...</span></code></pre></div>
<div id="references-3" class="section level4">
<h4>References:</h4>
<p>Rosenwald A, Wright G, Chan WC, et al. The use of molecular profiling to predict survival after chemotherapy for diffuse large-B-cell lymphoma. N Engl J Med 2002;346(25):1937-1947</p>
</div>
</div>
<div id="rosenwald.expr" class="section level3">
<h3>2). rosenwald.expr</h3>
<p>This data matrix contains Lymphochip microarrays expression data for the 60 Diffuse Large B-Cell Lymphomas samples as described in rosenwald.cli.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">"rosenwald.expr"</span>)
<span class="kw">str</span>(rosenwald.expr)
<span class="co">#&gt;  num [1:7399, 1:60] 0.607 0.239 0.828 0.932 0.86 0 0.476 0.814 0.81 0.87 ...</span>
<span class="co">#&gt;  - attr(*, "dimnames")=List of 2</span>
<span class="co">#&gt;   ..$ : chr [1:7399] "27481" "17013" "24751" "27498" ...</span>
<span class="co">#&gt;   ..$ : chr [1:60] "LYM018" "LYM120" "LYM180" "LYM285" ...</span></code></pre></div>
<div id="references-4" class="section level4">
<h4>References:</h4>
<p>Rosenwald A, Wright G, Chan WC, et al. The use of molecular profiling to predict survival after chemotherapy for diffuse large-B-cell lymphoma. N Engl J Med 2002;346(25):1937-1947</p>
</div>
</div>
<div id="wrightcoo" class="section level3">
<h3>3). WrightCOO</h3>
<p>This data frame contains 158 COO (cell of origin) related genes with both Ensembl annotation ID (row names) and gene symbols (column “Gene”). These genes are used to classfy DLBCL samples into GCB, ABC, or UNC.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">"WrightCOO"</span>)
<span class="kw">str</span>(WrightCOO)
<span class="co">#&gt; 'data.frame':    158 obs. of  1 variable:</span>
<span class="co">#&gt;  $ Gene: chr  "NR3C1" "PMM2" "STS" "BCL2" ...</span>
<span class="kw">head</span>(WrightCOO)
<span class="co">#&gt;                  Gene</span>
<span class="co">#&gt; ENSG00000113580 NR3C1</span>
<span class="co">#&gt; ENSG00000140650  PMM2</span>
<span class="co">#&gt; ENSG00000101846   STS</span>
<span class="co">#&gt; ENSG00000171791  BCL2</span>
<span class="co">#&gt; ENSG00000168811 IL12A</span>
<span class="co">#&gt; ENSG00000196549   MME</span></code></pre></div>
<div id="references-5" class="section level4">
<h4>References:</h4>
<p>Wright G, Tan B, Rosenwald A, Hurt EH, Wiestner A, Staudt LM. A trait expression-based method to diagnose clinically distinct subgroups of diffuse large B cell lymphoma. Proc Natl Acad Sci U S A. 2003 Aug 19;100(17):9991-6.</p>
</div>
</div>
<div id="dhitsiggenes" class="section level3">
<h3>4). DHITsigGenes</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">"DHITsigGenes"</span>)
<span class="kw">str</span>(DHITsigGenes)
<span class="co">#&gt; 'data.frame':    104 obs. of  1 variable:</span>
<span class="co">#&gt;  $ Genes: chr  "OR13A1" "FAM216A" "MYC" "SLC25A27" ...</span>
<span class="kw">head</span>(DHITsigGenes)
<span class="co">#&gt;      Genes</span>
<span class="co">#&gt; 1   OR13A1</span>
<span class="co">#&gt; 2  FAM216A</span>
<span class="co">#&gt; 3      MYC</span>
<span class="co">#&gt; 4 SLC25A27</span>
<span class="co">#&gt; 5    ALOX5</span>
<span class="co">#&gt; 6    UQCRH</span></code></pre></div>
<div id="references-6" class="section level4">
<h4>References:</h4>
<p>Ennishi D, Jiang A, Boyle M, Collinge B, Grande BM, Ben-Neriah S, Rushton C, Tang J, Thomas N, Slack GW, Farinha P, Takata K, Miyata-Takata T, Craig J, Mottok A, Meissner B, Saberi S, Bashashati A, Villa D, Savage KJ, Sehn LH, Kridel R, Mungall AJ, Marra MA, Shah SP, Steidl C, Connors JM, Gascoyne RD, Morin RD, Scott DW. Double-Hit Trait Expression Signature Defines a Distinct Subgroup of Germinal Center B-Cell-Like Diffuse Large B-Cell Lymphoma. J Clin Oncol. 2018 Dec 3:JCO1801583. doi: 10.1200/JCO.18.01583.</p>
</div>
</div>
</div>
<div id="example-code" class="section level2">
<h2>3. Example code</h2>
<p>In this section, we are providing example code to get classification score when training and testing data are comparable</p>
<div id="lps" class="section level3">
<h3>1) LPS</h3>
<div id="lpstraining" class="section level4">
<h4>LPStraining</h4>
<p>Get the data ready:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">group =<span class="st"> </span>rosenwald.cli$group
dat =<span class="st"> </span>rosenwald.expr</code></pre></div>
<p>Use GCB as a reference group as in LPS package, then LPStraining result can be got as following</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nin =<span class="st"> </span><span class="dv">100</span> 
trainLPS =<span class="st"> </span><span class="kw">LPStraining</span> (<span class="dt">trainDat =</span> dat, <span class="dt">groupInfo =</span> group, <span class="dt">refGroup =</span> <span class="st">"GCB"</span>, <span class="dt">topN =</span> nin,
                      <span class="dt">weightMethod =</span> <span class="st">"ttest"</span>)
<span class="kw">str</span>(trainLPS)
<span class="co">#&gt; List of 4</span>
<span class="co">#&gt;  $ LPS_pars    :List of 2</span>
<span class="co">#&gt;   ..$ weights:'data.frame':  100 obs. of  3 variables:</span>
<span class="co">#&gt;   .. ..$ tValue: num [1:100] 8.33 8.37 8 7.86 -8.01 ...</span>
<span class="co">#&gt;   .. ..$ pValue: num [1:100] 2.24e-11 1.86e-11 6.22e-11 1.35e-10 1.76e-10 ...</span>
<span class="co">#&gt;   .. ..$ FDR   : num [1:100] 8.29e-08 8.29e-08 1.53e-07 2.49e-07 2.60e-07 ...</span>
<span class="co">#&gt;   ..$ meansds: Named num [1:4] 454 -294 125 187</span>
<span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:4] "testLPSmean" "refLPSmean" "testLPSsd" "refLPSsd"</span>
<span class="co">#&gt;  $ LPS_train   :'data.frame':    60 obs. of  5 variables:</span>
<span class="co">#&gt;   ..$ LPS_score    : num [1:60] -398.71 384.84 468.91 -5.58 -208.42 ...</span>
<span class="co">#&gt;   ..$ true_class   : Factor w/ 2 levels "ABC","GCB": 2 1 1 2 2 2 1 2 1 1 ...</span>
<span class="co">#&gt;   ..$ LPS_class    : chr [1:60] "GCB" "ABC" "ABC" "GCB" ...</span>
<span class="co">#&gt;   ..$ LPS_prob_test: num [1:60] 1.32e-10 9.99e-01 1.00 5.55e-03 1.29e-06 ...</span>
<span class="co">#&gt;   ..$ LPS_prob_ref : num [1:60] 1 0.0011 0.000169 0.994446 0.999999 ...</span>
<span class="co">#&gt;  $ classCompare:List of 6</span>
<span class="co">#&gt;   ..$ positive: chr "ABC"</span>
<span class="co">#&gt;   ..$ table   : 'table' int [1:2, 1:2] 37 0 0 22</span>
<span class="co">#&gt;   .. ..- attr(*, "dimnames")=List of 2</span>
<span class="co">#&gt;   .. .. ..$ Prediction: chr [1:2] "GCB" "ABC"</span>
<span class="co">#&gt;   .. .. ..$ Reference : chr [1:2] "GCB" "ABC"</span>
<span class="co">#&gt;   ..$ overall : Named num [1:7] 1 1 0.939 1 0.627 ...</span>
<span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:7] "Accuracy" "Kappa" "AccuracyLower" "AccuracyUpper" ...</span>
<span class="co">#&gt;   ..$ byClass : Named num [1:11] 1 1 1 1 1 ...</span>
<span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:11] "Sensitivity" "Specificity" "Pos Pred Value" "Neg Pred Value" ...</span>
<span class="co">#&gt;   ..$ mode    : chr "sens_spec"</span>
<span class="co">#&gt;   ..$ dots    : list()</span>
<span class="co">#&gt;   ..- attr(*, "class")= chr "confusionMatrix"</span>
<span class="co">#&gt;  $ classTable  : 'table' int [1:2, 1:3] 0 22 37 0 0 1</span>
<span class="co">#&gt;   ..- attr(*, "dimnames")=List of 2</span>
<span class="co">#&gt;   .. ..$ groupInfo: chr [1:2] "GCB" "ABC"</span>
<span class="co">#&gt;   .. ..$ LPS_class: chr [1:3] "ABC" "GCB" "UNCLASS"</span></code></pre></div>
<p>The last item in the output of LPStraining provides information on how our LPS prediction model is doing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trainLPS$classTable
<span class="co">#&gt;          LPS_class</span>
<span class="co">#&gt; groupInfo ABC GCB UNCLASS</span>
<span class="co">#&gt;       GCB   0  37       0</span>
<span class="co">#&gt;       ABC  22   0       1</span></code></pre></div>
<p>This means with given COO info, and with top 100 significant genes based on t test, LPS classification can put all GCB samples back to GCB samples, for ABC samples, however, one of them is put into UNCLASS, all other samples are put back into ABC.</p>
<p>More detail information about LPStraining function can be found with the two choices:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?(LPStraining)
<span class="kw">help</span>(LPStraining)</code></pre></div>
</div>
<div id="lpstesting" class="section level4">
<h4>LPStesting</h4>
<p>Now, we need to have a testing data set that is comparable to the training data set. As an example, we get a bootstrap sample set with a given N to build our psuedo testing data set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1027562</span>)
N =<span class="st"> </span><span class="dv">200</span>  ### sample size for testing
testdat =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">dim</span>(dat)[<span class="dv">2</span>], <span class="dt">size =</span> N, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
testdat =<span class="st"> </span>dat[, testdat]
<span class="kw">str</span>(testdat)
<span class="co">#&gt;  num [1:7399, 1:200] -1.46 -1.51 -1.48 -1.43 -1.65 ...</span>
<span class="co">#&gt;  - attr(*, "dimnames")=List of 2</span>
<span class="co">#&gt;   ..$ : chr [1:7399] "27481" "17013" "24751" "27498" ...</span>
<span class="co">#&gt;   ..$ : chr [1:200] "LYM112" "LYM197" "LYM142" "LYM430" ...</span></code></pre></div>
<p>Now, we can use the output from LPStraining and the testdat for LPStesting</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testLPS =<span class="st"> </span><span class="kw">LPStesting</span>(<span class="dt">LPStrainObj =</span> trainLPS, <span class="dt">newdat =</span> testdat)
<span class="kw">str</span>(testLPS)
<span class="co">#&gt; 'data.frame':    200 obs. of  4 variables:</span>
<span class="co">#&gt;  $ LPS_score    : num  -393.5 -625.8 -289.8 -279.4 -22.9 ...</span>
<span class="co">#&gt;  $ LPS_class    : chr  "GCB" "GCB" "GCB" "GCB" ...</span>
<span class="co">#&gt;  $ LPS_prob_test: num  1.72e-10 4.20e-16 2.96e-08 4.85e-08 2.88e-03 ...</span>
<span class="co">#&gt;  $ LPS_prob_ref : num  1 1 1 1 0.997 ...</span>
<span class="kw">table</span>(testLPS$LPS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt;     ABC     GCB UNCLASS </span>
<span class="co">#&gt;      74     124       2</span></code></pre></div>
<p>We can also combine training and testing data sets together for testing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fullLPS =<span class="st"> </span><span class="kw">LPStesting</span>(<span class="dt">LPStrainObj =</span> trainLPS, <span class="dt">newdat =</span> <span class="kw">cbind</span>(testdat, dat))
<span class="kw">str</span>(fullLPS)
<span class="co">#&gt; 'data.frame':    260 obs. of  4 variables:</span>
<span class="co">#&gt;  $ LPS_score    : num  -393.5 -625.8 -289.8 -279.4 -22.9 ...</span>
<span class="co">#&gt;  $ LPS_class    : chr  "GCB" "GCB" "GCB" "GCB" ...</span>
<span class="co">#&gt;  $ LPS_prob_test: num  1.72e-10 4.20e-16 2.96e-08 4.85e-08 2.88e-03 ...</span>
<span class="co">#&gt;  $ LPS_prob_ref : num  1 1 1 1 0.997 ...</span>
<span class="kw">table</span>(fullLPS$LPS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt;     ABC     GCB UNCLASS </span>
<span class="co">#&gt;      96     161       3</span></code></pre></div>
<p>Now, we are wondering if the testLPS and fulltest give us consistent results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(testLPS$LPS_class, fullLPS$LPS_class[<span class="dv">1</span>:N])
<span class="co">#&gt;          </span>
<span class="co">#&gt;           ABC GCB UNCLASS</span>
<span class="co">#&gt;   ABC      74   0       0</span>
<span class="co">#&gt;   GCB       0 124       0</span>
<span class="co">#&gt;   UNCLASS   0   0       2</span></code></pre></div>
<p>More detail about LPStesting can be found with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?(LPStesting)
<span class="kw">help</span>(LPStesting)</code></pre></div>
</div>
</div>
<div id="prps" class="section level3">
<h3>2) PRPS</h3>
<div id="prpstraining" class="section level4">
<h4>PRPStraining</h4>
<p>Use the same training data set: <em>dat</em> as above, and use GCB as a reference group as in LPS package, then PRPStraining result can be got as following. Notice that now we are calling PRPStraining but all setting is the same as for LPStraining</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nin =<span class="st"> </span><span class="dv">100</span> 
trainPRPS =<span class="st"> </span><span class="kw">PRPStraining</span> (<span class="dt">trainDat =</span> dat, <span class="dt">groupInfo =</span> group, <span class="dt">refGroup =</span> <span class="st">"GCB"</span>, <span class="dt">topN =</span> nin,
                      <span class="dt">weightMethod =</span> <span class="st">"ttest"</span>)
<span class="kw">str</span>(trainPRPS)
<span class="co">#&gt; List of 4</span>
<span class="co">#&gt;  $ PRPS_pars   :List of 3</span>
<span class="co">#&gt;   ..$ weights      :'data.frame':    100 obs. of  3 variables:</span>
<span class="co">#&gt;   .. ..$ tValue: num [1:100] 8.33 8.37 8 7.86 -8.01 ...</span>
<span class="co">#&gt;   .. ..$ pValue: num [1:100] 2.24e-11 1.86e-11 6.22e-11 1.35e-10 1.76e-10 ...</span>
<span class="co">#&gt;   .. ..$ FDR   : num [1:100] 8.29e-08 8.29e-08 1.53e-07 2.49e-07 2.60e-07 ...</span>
<span class="co">#&gt;   ..$ meansds      : Named num [1:4] 113.6 -151.6 42.5 66.3</span>
<span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:4] "testPRPSmean" "refPRPSmean" "testPRPSsd" "refPRPSsd"</span>
<span class="co">#&gt;   ..$ traitsmeansds: num [1:100, 1:4] 0.328 0.437 0.388 0.403 -1.258 ...</span>
<span class="co">#&gt;   .. ..- attr(*, "dimnames")=List of 2</span>
<span class="co">#&gt;   .. .. ..$ : chr [1:100] "27562" "17708" "24796" "27458" ...</span>
<span class="co">#&gt;   .. .. ..$ : chr [1:4] "testmean" "refmean" "testsd" "refsd"</span>
<span class="co">#&gt;  $ PRPS_train  :'data.frame':    60 obs. of  6 variables:</span>
<span class="co">#&gt;   ..$ PRPS_score    : num [1:60] -158.6 99.5 149.9 -78.7 -106.5 ...</span>
<span class="co">#&gt;   ..$ true_class    : Factor w/ 2 levels "ABC","GCB": 2 1 1 2 2 2 1 2 1 1 ...</span>
<span class="co">#&gt;   ..$ PRPS_class    : chr [1:60] "GCB" "ABC" "ABC" "GCB" ...</span>
<span class="co">#&gt;   ..$ PRPS_prob_test: num [1:60] 1.85e-09 9.99e-01 1.00 9.99e-05 2.87e-06 ...</span>
<span class="co">#&gt;   ..$ PRPS_prob_ref : num [1:60] 1.00 5.15e-04 2.95e-05 1.00 1.00 ...</span>
<span class="co">#&gt;   ..$ PRPS_class0   : chr [1:60] "GCB" "ABC" "ABC" "GCB" ...</span>
<span class="co">#&gt;  $ classCompare:List of 6</span>
<span class="co">#&gt;   ..$ positive: chr "ABC"</span>
<span class="co">#&gt;   ..$ table   : 'table' int [1:2, 1:2] 37 0 0 23</span>
<span class="co">#&gt;   .. ..- attr(*, "dimnames")=List of 2</span>
<span class="co">#&gt;   .. .. ..$ Prediction: chr [1:2] "GCB" "ABC"</span>
<span class="co">#&gt;   .. .. ..$ Reference : chr [1:2] "GCB" "ABC"</span>
<span class="co">#&gt;   ..$ overall : Named num [1:7] 1 1 0.94 1 0.617 ...</span>
<span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:7] "Accuracy" "Kappa" "AccuracyLower" "AccuracyUpper" ...</span>
<span class="co">#&gt;   ..$ byClass : Named num [1:11] 1 1 1 1 1 ...</span>
<span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:11] "Sensitivity" "Specificity" "Pos Pred Value" "Neg Pred Value" ...</span>
<span class="co">#&gt;   ..$ mode    : chr "sens_spec"</span>
<span class="co">#&gt;   ..$ dots    : list()</span>
<span class="co">#&gt;   ..- attr(*, "class")= chr "confusionMatrix"</span>
<span class="co">#&gt;  $ classTable  : 'table' int [1:2, 1:2] 0 23 37 0</span>
<span class="co">#&gt;   ..- attr(*, "dimnames")=List of 2</span>
<span class="co">#&gt;   .. ..$ groupInfo : chr [1:2] "GCB" "ABC"</span>
<span class="co">#&gt;   .. ..$ PRPS_class: chr [1:2] "ABC" "GCB"</span></code></pre></div>
<p>The last item in the output of PRPStraining provides information on how our PRPS prediction model is doing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trainPRPS$classTable
<span class="co">#&gt;          PRPS_class</span>
<span class="co">#&gt; groupInfo ABC GCB</span>
<span class="co">#&gt;       GCB   0  37</span>
<span class="co">#&gt;       ABC  23   0</span></code></pre></div>
<p>This means with given COO info, and with top 100 significant genes based on t test, PRPS classification is 100% matching to given COO.</p>
<p>More detail information about LPStraining function can be found with the two choices:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?(PRPStraining)
<span class="kw">help</span>(PRPStraining)</code></pre></div>
</div>
<div id="prpstesting" class="section level4">
<h4>PRPStesting</h4>
<p>With the exact same testing data set: <em>testdat</em>, use the output from PRPStraining, we can apply PRPStesting as following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testPRPS =<span class="st"> </span><span class="kw">PRPStesting</span>(<span class="dt">PRPStrainObj =</span> trainPRPS, <span class="dt">newdat =</span> testdat)
<span class="kw">str</span>(testPRPS)
<span class="co">#&gt; 'data.frame':    200 obs. of  5 variables:</span>
<span class="co">#&gt;  $ PRPS_score    : num  -162 -223 -112 -190 -48 ...</span>
<span class="co">#&gt;  $ PRPS_class    : chr  "GCB" "GCB" "GCB" "GCB" ...</span>
<span class="co">#&gt;  $ PRPS_prob_test: num  1.18e-09 6.66e-14 1.32e-06 1.38e-11 3.77e-03 ...</span>
<span class="co">#&gt;  $ PRPS_prob_ref : num  1 1 1 1 0.996 ...</span>
<span class="co">#&gt;  $ PRPS_class0   : chr  "GCB" "GCB" "GCB" "GCB" ...</span>
<span class="kw">table</span>(testPRPS$PRPS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt; ABC GCB </span>
<span class="co">#&gt;  76 124</span></code></pre></div>
<p>We can also combine training and testing data sets together for testing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fullPRPS =<span class="st"> </span><span class="kw">PRPStesting</span>(<span class="dt">PRPStrainObj =</span> trainPRPS, <span class="dt">newdat =</span> <span class="kw">cbind</span>(testdat, dat))
<span class="kw">str</span>(fullPRPS)
<span class="co">#&gt; 'data.frame':    260 obs. of  5 variables:</span>
<span class="co">#&gt;  $ PRPS_score    : num  -162 -223 -112 -190 -48 ...</span>
<span class="co">#&gt;  $ PRPS_class    : chr  "GCB" "GCB" "GCB" "GCB" ...</span>
<span class="co">#&gt;  $ PRPS_prob_test: num  1.18e-09 6.66e-14 1.32e-06 1.38e-11 3.77e-03 ...</span>
<span class="co">#&gt;  $ PRPS_prob_ref : num  1 1 1 1 0.996 ...</span>
<span class="co">#&gt;  $ PRPS_class0   : chr  "GCB" "GCB" "GCB" "GCB" ...</span>
<span class="kw">table</span>(fullPRPS$PRPS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt; ABC GCB </span>
<span class="co">#&gt;  99 161</span></code></pre></div>
<p>Now, we are wondering if the testLPS and fulltest give us consistent results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(testPRPS$PRPS_class, fullPRPS$PRPS_class[<span class="dv">1</span>:N])
<span class="co">#&gt;      </span>
<span class="co">#&gt;       ABC GCB</span>
<span class="co">#&gt;   ABC  76   0</span>
<span class="co">#&gt;   GCB   0 124</span></code></pre></div>
<p>If we compare PRPS results with LPS results, we can find that there is 1 UNCLASS in LPStraining output and there are 2 UNCLASS in LPStesting output, however, there is no UNCLASS in either PRPStraining or PRPStesting output. Remember that our <em>dat</em> contains no UNCLASS samples, and our <em>testdat</em> are bootstrapped from <em>dat</em>, therefore, there should be no UNCLASS either in <em>testdat</em>. Together, we think that PRPS might be a slightly better approach than LPS.</p>
</div>
</div>
<div id="ps" class="section level3">
<h3>3) PS</h3>
<div id="pstraining" class="section level4">
<h4>PStraining</h4>
<p>Use the same training data set: <em>dat</em> as above, and use GCB as a reference group as in LPS package, then PStraining result can be got as following. Notice that now we are calling PStraining but all setting is the same as for LPStraining</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nin =<span class="st"> </span><span class="dv">100</span> 
trainPS =<span class="st"> </span><span class="kw">PStraining</span> (<span class="dt">trainDat =</span> dat, <span class="dt">groupInfo =</span> group, <span class="dt">refGroup =</span> <span class="st">"GCB"</span>, <span class="dt">topN =</span> nin,
                         <span class="dt">weightMethod =</span> <span class="st">"ttest"</span>)
<span class="kw">str</span>(trainPS)
<span class="co">#&gt; List of 4</span>
<span class="co">#&gt;  $ PS_pars     :'data.frame':    100 obs. of  6 variables:</span>
<span class="co">#&gt;   ..$ meanOfGroupMeans: num [1:100] 0.157 0.161 0.162 0.165 -0.186 ...</span>
<span class="co">#&gt;   ..$ tValue          : num [1:100] 8.33 8.37 8 7.86 -8.01 ...</span>
<span class="co">#&gt;   ..$ refGroupMean    : num [1:100] -0.554 -0.569 -0.533 -0.543 0.546 ...</span>
<span class="co">#&gt;   ..$ testGroupMean   : num [1:100] 0.867 0.89 0.858 0.873 -0.919 ...</span>
<span class="co">#&gt;   ..$ pValue          : num [1:100] 2.24e-11 1.86e-11 6.22e-11 1.35e-10 1.76e-10 ...</span>
<span class="co">#&gt;   ..$ FDR             : num [1:100] 8.29e-08 8.29e-08 1.53e-07 2.49e-07 2.60e-07 ...</span>
<span class="co">#&gt;  $ PS_train    :'data.frame':    60 obs. of  3 variables:</span>
<span class="co">#&gt;   ..$ PS_score  : num [1:60] -0.726 0.632 0.889 -0.454 -0.563 ...</span>
<span class="co">#&gt;   ..$ true_class: Factor w/ 2 levels "ABC","GCB": 2 1 1 2 2 2 1 2 1 1 ...</span>
<span class="co">#&gt;   ..$ PS_class  : chr [1:60] "GCB" "ABC" "ABC" "GCB" ...</span>
<span class="co">#&gt;  $ classCompare:List of 6</span>
<span class="co">#&gt;   ..$ positive: chr "ABC"</span>
<span class="co">#&gt;   ..$ table   : 'table' int [1:2, 1:2] 37 0 0 23</span>
<span class="co">#&gt;   .. ..- attr(*, "dimnames")=List of 2</span>
<span class="co">#&gt;   .. .. ..$ Prediction: chr [1:2] "GCB" "ABC"</span>
<span class="co">#&gt;   .. .. ..$ Reference : chr [1:2] "GCB" "ABC"</span>
<span class="co">#&gt;   ..$ overall : Named num [1:7] 1 1 0.94 1 0.617 ...</span>
<span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:7] "Accuracy" "Kappa" "AccuracyLower" "AccuracyUpper" ...</span>
<span class="co">#&gt;   ..$ byClass : Named num [1:11] 1 1 1 1 1 ...</span>
<span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:11] "Sensitivity" "Specificity" "Pos Pred Value" "Neg Pred Value" ...</span>
<span class="co">#&gt;   ..$ mode    : chr "sens_spec"</span>
<span class="co">#&gt;   ..$ dots    : list()</span>
<span class="co">#&gt;   ..- attr(*, "class")= chr "confusionMatrix"</span>
<span class="co">#&gt;  $ classTable  : 'table' int [1:2, 1:2] 37 0 0 23</span>
<span class="co">#&gt;   ..- attr(*, "dimnames")=List of 2</span>
<span class="co">#&gt;   .. ..$ groupInfo: chr [1:2] "GCB" "ABC"</span>
<span class="co">#&gt;   .. ..$ PS_class : chr [1:2] "GCB" "ABC"</span></code></pre></div>
<p>The last item in the output of PStraining provides information on how our PS prediction model is doing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trainPS$classTable
<span class="co">#&gt;          PS_class</span>
<span class="co">#&gt; groupInfo GCB ABC</span>
<span class="co">#&gt;       GCB  37   0</span>
<span class="co">#&gt;       ABC   0  23</span></code></pre></div>
<p>This means with given COO info, and with top 100 significant genes based on t test, PS classification is 100% matching to given COO.</p>
<p>More detail information about LPStraining function can be found with the two choices:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?(PStraining)
<span class="kw">help</span>(PStraining)</code></pre></div>
</div>
<div id="pstesting" class="section level4">
<h4>PStesting</h4>
<p>With the exact same testing data set: <em>testdat</em>, use the output from PStraining, we can apply PStesting as following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testPS =<span class="st"> </span><span class="kw">PStesting</span>(<span class="dt">PStrainObj =</span> trainPS, <span class="dt">newdat =</span> testdat)
<span class="kw">str</span>(testPS)
<span class="co">#&gt; 'data.frame':    200 obs. of  2 variables:</span>
<span class="co">#&gt;  $ PS_score: num  -0.857 -0.935 -0.696 -0.9 -0.146 ...</span>
<span class="co">#&gt;  $ PS_class: chr  "GCB" "GCB" "GCB" "GCB" ...</span>
<span class="kw">table</span>(testPS$PS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt; ABC GCB </span>
<span class="co">#&gt;  76 124</span></code></pre></div>
<p>We can also combine training and testing data sets together for testing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fullPS =<span class="st"> </span><span class="kw">PStesting</span>(<span class="dt">PStrainObj =</span> trainPS, <span class="dt">newdat =</span> <span class="kw">cbind</span>(testdat, dat))
<span class="kw">str</span>(fullPS)
<span class="co">#&gt; 'data.frame':    260 obs. of  2 variables:</span>
<span class="co">#&gt;  $ PS_score: num  -0.859 -0.935 -0.699 -0.9 -0.149 ...</span>
<span class="co">#&gt;  $ PS_class: chr  "GCB" "GCB" "GCB" "GCB" ...</span>
<span class="kw">table</span>(fullPS$PS_class)
<span class="co">#&gt; </span>
<span class="co">#&gt; ABC GCB </span>
<span class="co">#&gt;  99 161</span></code></pre></div>
<p>Now, we are wondering if the testLPS and fulltest give us consistent results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(testPS$PS_class, fullPS$PS_class[<span class="dv">1</span>:N])
<span class="co">#&gt;      </span>
<span class="co">#&gt;       ABC GCB</span>
<span class="co">#&gt;   ABC  76   0</span>
<span class="co">#&gt;   GCB   0 124</span></code></pre></div>
<p>PS performs exactly the same as PRPS for the above training and testing data sets (<em>dat</em> and <em>testdat</em>), and both of them might be better approaches than LPS</p>
</div>
</div>
</div>
</div>
<div id="iii.-special-path-classification-score-calculation-without-training" class="section level1">
<h1>III. Special path: classification score calculation without training</h1>
<p>If we already have selected features/traits and their parameters needed for classification score calculation, we might also calculate classification scores for a given data set without training data sets.</p>
<div id="when-weights-for-selected-featurestraits-testing-are-available" class="section level2">
<h2>1. when weights for selected features/traits + testing are available</h2>
<p>If we only know selected features/traits, but we do not know any further information. In this case, if we would like to calculate classification score for a given tesing data set, what can we do?</p>
<p>Without any further information and without any assumption, the only method we can use to calculate classification score is to apply LPS approach. In this case, we can call getClassScores and set method as LPS.</p>
<p>Assuming that we have features and their weights from some where, for example, we can get this information from trainLPS:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lpswts =<span class="st"> </span>trainLPS$LPS_pars$weights
<span class="kw">str</span>(lpswts)
<span class="co">#&gt; 'data.frame':    100 obs. of  3 variables:</span>
<span class="co">#&gt;  $ tValue: num  8.33 8.37 8 7.86 -8.01 ...</span>
<span class="co">#&gt;  $ pValue: num  2.24e-11 1.86e-11 6.22e-11 1.35e-10 1.76e-10 ...</span>
<span class="co">#&gt;  $ FDR   : num  8.29e-08 8.29e-08 1.53e-07 2.49e-07 2.60e-07 ...</span></code></pre></div>
<p>Here, the tValue is the weight for the top 100 genes selected with LPStraining.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">genes =<span class="st"> </span><span class="kw">rownames</span>(lpswts)
lpswts =<span class="st"> </span>lpswts[,<span class="dv">1</span>]
<span class="kw">names</span>(lpswts) =<span class="st"> </span>genes
<span class="kw">head</span>(lpswts)
<span class="co">#&gt;     27562     17708     24796     27458     17496     27631 </span>
<span class="co">#&gt;  8.329309  8.367778  8.002261  7.856705 -8.007235  7.745951</span></code></pre></div>
<p>With the same <em>testdat</em>, we can get LPS score with function: getClassScores</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lpsscores =<span class="st"> </span><span class="kw">getClassScores</span>(testdat, <span class="dt">classMethod =</span> <span class="st">"LPS"</span>, <span class="dt">weights =</span> lpswts)
<span class="kw">head</span>(lpsscores)
<span class="co">#&gt;     LYM112     LYM197     LYM142     LYM430     LYM164     LYM089 </span>
<span class="co">#&gt; -393.51715 -625.81619 -289.82814 -279.42530  -22.91124  543.56341</span></code></pre></div>
<p>While LPS score calculation only requires weights, in order to get classification, we need more information to help us. LPS classification is based on Empirical Bayes probabilities, which requires LPS score mean and sd for two groups (for the example data, GCB or ABC). In order to get these information, we might have two ways to achieve:</p>
<div id="section" class="section level3">
<h3>1)</h3>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>



</body></html>