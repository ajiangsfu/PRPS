\nonstopmode{}
\documentclass[letterpaper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8]{inputenc} % @SET ENCODING@
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `PRPS'}}
\par\bigskip{\large \today}
\end{center}
\begin{description}
\raggedright{}
\inputencoding{utf8}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{Calculate classification scores and classify samples into 2 to 3
groups}
\item[Version]\AsIs{0.1.0}
\item[Author]\AsIs{Aixiang Jiang}
\item[Maintainer]\AsIs{Aixiang Jiang }\email{aijiang@bccrc.ca}\AsIs{}
\item[Depends]\AsIs{R (>= 3.3.1)}
\item[Suggests]\AsIs{knitr}
\item[VignetteBuilder]\AsIs{knitr}
\item[Imports]\AsIs{lattice, caret, limma, e1071, pROC}
\item[Description]\AsIs{This package calculates classification prediction score with three method choices:
a) LPS (defult, Linear Prediction Score);
b) PRPS (Probability ratio based classification predication score);
c) PS (Prediction Strength).
In the classification step, if LPS is chosen, Empirical Bayes' probabilities are calcualted
and classification is based on cutoff on probabilities; if PRPS is chosen, two types of outputs
are given: one is based on cutoff on Empirical Bayes' probabilities, the other one is based on
natural cutoff 0 on PRPS scores; when PS is selected, by default, classification is based on
natural cutoff 0 on PS scores, however, a separate function can alos issues classification based
on cutoff on Empirical Bayes' probabilities when necessary.}
\item[License]\AsIs{MIT + file LICENSE}
\item[Encoding]\AsIs{UTF-8}
\item[LazyData]\AsIs{true}
\item[RoxygenNote]\AsIs{6.1.1}
\item[NeedsCompilation]\AsIs{no}
\end{description}
\Rdcontents{\R{} topics documented:}
\inputencoding{utf8}
\HeaderA{getClassScores}{Classification Score Calculation}{getClassScores}
\keyword{LPS}{getClassScores}
\keyword{PRPS}{getClassScores}
\keyword{PS}{getClassScores}
%
\begin{Description}\relax
This function is to calculate classification prediction score with three method choices: 
LPS (defult, Linear Prediction Score) or PRPS (Probability ratio based classification predication score) or PS (Prediction Strength).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getClassScores(testdat, classMethod = c("LPS", "PRPS", "PS"), weights,
  classMeans, classSds)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{testdat}] testing data set, a data matrix or a data frame, samples are in columns, and features/genes are in rows

\item[\code{classMethod}] three choices with defaul "LPS", the other two methods are "PRPS" and "PS"

\item[\code{weights}] a numeric vector of selected feature weights, which will be used for classfication score calculation,
this is required for all three methods

\item[\code{classMeans}] a two columns' data frame or data matrix, row names are the selected features that can be matched to testdat, 
columns are for group 1 (the 1st column) and group 0 (the 2nd column), the values are the group means for selected features, 
this is needed for PRPS and PS but not LPS

\item[\code{classSds}] a two columns' data frame or data matrix, row names are the selected features that can be matched to testdat, 
columns are for group 1 (the 1st column) and group 0 (the 2nd column), the values are the group sds for selected features, 
this is needed for PRPS but not LPS or PS
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
For the default method: LPS, the linear prediction scores are calculated. When PS is chosen, standardization is included 
before score calculation, and we assume that the input of classMeans is also calculated after standardization. 
Notice that this function only issue score values without classification. 
If there are NAs in the data and not imputed before calling this function, these NAs will be ignored for score calculation.
\eqn{LPS(X_i) = \sum a_j x_ij}{}
Here a\_j represents the jth selected feature weights, and x\_ij is the corresponding feature value for the ith sample.
When PRPS method is selected, probability ratio based classification prediction scores are calculated
\eqn{PRPS(X_i) = \sum (|a_j| log(P1(x_ij)/P0(x_ij)))}{}
Again, a\_j represents the jth selected feature weights, and x\_ij is the corresponding feature value for the ith sample, 
P1 and P0 are the probabilities that the ith sample belongs to two different group.
When PS method is selected, prediction scores are calculated
\eqn{PS = (V_win − V_lose)/(V_win + V_lose)}{}
Here, where V\_win and V\_lose are the vote totals for the winning and losing features/genes for a given sample
\end{Details}
%
\begin{Value}
A vector of classification predication score
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Wright G, Tan B, Rosenwald A, Hurt EH, Wiestner A, Staudt LM. A gene expression-based method to diagnose
clinically distinct subgroups of diffuse large B cell lymphoma. Proc Natl Acad Sci U S A. 2003;100(17):9991-6.

Golub, T. R. and Slonim, D. K. and Tamayo, P. and Huard, C. and Gaasenbeek, M. and Mesirov, J. P. and
Coller, H. and Loh, M. L. and Downing, J. R. and Caligiuri, M. A. and Bloomfield, C. D. and Lander, E. S.
Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring. 
Science. 1999; 286(5439): 531-7

Ennishi D, Jiang A, Boyle M, Collinge B, Grande BM, Ben-Neriah S, Rushton C, Tang J, Thomas N, Slack GW, Farinha P,
Takata K, Miyata-Takata T, Craig J, Mottok A, Meissner B, Saberi S, Bashashati A, Villa D, Savage KJ, Sehn LH, 
Kridel R, Mungall AJ, Marra MA, Shah SP, Steidl C, Connors JM, Gascoyne RD, Morin RD, Scott DW. 
Double-Hit Gene Expression Signature Defines a Distinct Subgroup of Germinal Center B-Cell-Like Diffuse Large B-Cell Lymphoma.
J Clin Oncol. 2018 Dec 3:JCO1801583. doi: 10.1200/JCO.18.01583.
\end{References}
\inputencoding{utf8}
\HeaderA{getLPSscore}{LPS score calculation for a given sample}{getLPSscore}
\keyword{LPS}{getLPSscore}
%
\begin{Description}\relax
This is an internal function to calculate LPS (Linear Prediction Score),
which is called by other functions but it can also be called directly.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getLPSscore(vdat, coefs)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{vdat}] a numeric vector for all selected features for a given sample

\item[\code{coefs}] a numeric vector of weights for all selected features, 
which should be the same order as in "vdat"
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
LPS calculation is based on Wright 2003, the formula is staightforward:
\eqn{LPS(X) = \sum a_j X_j}{}
If NAs are not imputed, they are ignored for LPS calculation.
\end{Details}
%
\begin{Value}
A LPS score
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Wright G, Tan B, Rosenwald A, Hurt EH, Wiestner A, Staudt LM. A gene expression-based method
to diagnose clinically distinct subgroups of diffuse large B cell lymphoma. Proc Natl Acad Sci U S
A. 2003 Aug 19;100(17):9991-6.
\end{References}
\inputencoding{utf8}
\HeaderA{getMeanOfGroupMeans}{Mean of two groups' means calculation}{getMeanOfGroupMeans}
\keyword{mean}{getMeanOfGroupMeans}
\keyword{sd}{getMeanOfGroupMeans}
%
\begin{Description}\relax
This is an internal function called by PStraining to calculate mean of two groups' means for a feature,
which is needed for PS appraoch. However, it can be called directly if you do not have PStraining object but want to calcualate
PS scores, in this case, however, please make sure that you have get subset of selected features data only as traitdat, and
provide groupInfo and refGroup, then, the output of this function can be used to get PS scores via getClassScores function.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getMeanOfGroupMeans(traitdat, groupInfo, refGroup = 0)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{traitdat}] a vector of data for a single feature

\item[\code{groupInfo}] a known group classification, which sample order should be the same as for traitdat

\item[\code{refGroup}] the code for reference group, default is 0, but it can be a string or other number, 
which will be changed to 0 within the function
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
When mean of each group feature data is calculated, the NAs are removed.
\end{Details}
%
\begin{Value}
A numerical vector of mean of two group means, and the two group means
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
\inputencoding{utf8}
\HeaderA{getMeanSdAllTraits}{Group mean and standard deviation calculation for all selected features}{getMeanSdAllTraits}
\keyword{mean}{getMeanSdAllTraits}
\keyword{prior}{getMeanSdAllTraits}
\keyword{sd}{getMeanSdAllTraits}
%
\begin{Description}\relax
This is a wrap-up function to get group mean and sd for two groups and for all selected features.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getMeanSdAllTraits(testdat, selectedTraits, selectedTraitWeights,
  group1ratioPrior = 0.5)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{testdat}] a data matrix with columns for samples and rows for features

\item[\code{selectedTraits}] a selected feature list

\item[\code{group1ratioPrior}] a prior ratio to indicate the ratio of test group over reference group 
regarding mean and sd calculation for each selected feature

\item[\code{selectedtraitWeights}] a numeric vector with weight for all selected features, 
which are in the same order as selectedtraits, however, only the sign of weight is used in this function
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This is specifically designed for PRPS approach, however, it can be applied for other methods as well when 
group information is unknown, or mean and sd info from previous data can not be used in current data set 
due to data not comparable
\end{Details}
%
\begin{Value}
A numeric matrix of two group means and sds for all selected traits
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Ennishi D, Jiang A, Boyle M, Collinge B, Grande BM, Ben-Neriah S, Rushton C, Tang J, Thomas N, Slack GW, Farinha P,
Takata K, Miyata-Takata T, Craig J, Mottok A, Meissner B, Saberi S, Bashashati A, Villa D, Savage KJ, Sehn LH, 
Kridel R, Mungall AJ, Marra MA, Shah SP, Steidl C, Connors JM, Gascoyne RD, Morin RD, Scott DW. 
Double-Hit Gene Expression Signature Defines a Distinct Subgroup of Germinal Center B-Cell-Like Diffuse Large B-Cell Lymphoma.
J Clin Oncol. 2018 Dec 3:JCO1801583. doi: 10.1200/JCO.18.01583.
\end{References}
\inputencoding{utf8}
\HeaderA{getMeanSdPerTrait}{Group mean and standard deviation calculation for a given feature}{getMeanSdPerTrait}
\keyword{mean}{getMeanSdPerTrait}
\keyword{prior}{getMeanSdPerTrait}
\keyword{sd}{getMeanSdPerTrait}
%
\begin{Description}\relax
This is a function to get group mean and sd for two groups and for a given feature
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getMeanSdPerTrait(atrait, aweight, fulldat, ratioPrior = 0.5)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{atrait}] a given feature name

\item[\code{aweight}] weight for a given feature, only the sign of weight is used in this function

\item[\code{fulldat}] a data matrix with columns for samples and rows for features

\item[\code{ratioPrior}] a prior ratio to indicate the ratio of test group over reference group 
regarding mean and sd calculation for each selected feature
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This is specifically designed for PRPS approach, however, it can be applied for other methods as well when 
group information is unknown, or mean and sd info from previous data can not be used in current data set 
due to data not comparable
\end{Details}
%
\begin{Value}
A numeric vector of two group means and sds
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Ennishi D, Jiang A, Boyle M, Collinge B, Grande BM, Ben-Neriah S, Rushton C, Tang J, Thomas N, Slack GW, Farinha P,
Takata K, Miyata-Takata T, Craig J, Mottok A, Meissner B, Saberi S, Bashashati A, Villa D, Savage KJ, Sehn LH, 
Kridel R, Mungall AJ, Marra MA, Shah SP, Steidl C, Connors JM, Gascoyne RD, Morin RD, Scott DW. 
Double-Hit Gene Expression Signature Defines a Distinct Subgroup of Germinal Center B-Cell-Like Diffuse Large B-Cell Lymphoma.
J Clin Oncol. 2018 Dec 3:JCO1801583. doi: 10.1200/JCO.18.01583.
\end{References}
\inputencoding{utf8}
\HeaderA{getProb}{Empirical Bayes' probability calculation}{getProb}
\keyword{Bayes'}{getProb}
\keyword{Empirical}{getProb}
\keyword{probability}{getProb}
%
\begin{Description}\relax
This is a function to calculate Empirical Bayes' probability, 
which is called by other functions but it can also be called directly.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getProb(inscore, groupMeans, groupSds)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{inscore}] a classification score, which can be any types of scores

\item[\code{groupMeans}] a numeric vector of two items: two classification score means for two training groups/classes

\item[\code{groupSds}] a numeric vector of two items: two classification score standard deviations for two training groups/classes
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The coding is written based on Wright 2003 for LPS (linear predication score) approach, 
but it can be used for other appraoches such as PS and PRPS as well. 
For LPS, the probability step is required since LPS itself does not have a natural cutoff for classification, 
alternatively, if the testing and training data arec comparable, we can also make classification based on LPS cutoffs 
but this is not commonly used. For PS and PRPS, 0 is a natural cutoff for two group classification, however, 
this probability step is still useful if we allow UNCLASS group in the final classification besides the two types 
of classes from the training.
When calculate a Empirical Bayes' probability, the 1st group in the input mean and sd vectors is treated as the test group. 
When calculate the probabilities, we first calcualte probability that a sample belongs to either group, and then:
\eqn{prob(x) = p_test(x)/(p_test(x) + p_ref(x))}{}
Here prob(x) is the Empirical Bayes' probability of a given sample, p\_test(x) is the probability that a given sample 
belongs to the test group, p\_ref(x) is the probability that a given sample belongs to the reference group.
Notice that the test and reference group is just the relative grouping, in fact, for this step, 
we often need to calculate Empirical Bayes' probabilities for a given sample from two different standing points.
If you need to calculate Empirical Bayes' probabilities of a group of samples, "apply" function is needed to get all done.
\end{Details}
%
\begin{Value}
A probability for a sample belong to a group
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Wright G, Tan B, Rosenwald A, Hurt EH, Wiestner A, Staudt LM. A gene expression-based method
to diagnose clinically distinct subgroups of diffuse large B cell lymphoma. Proc Natl Acad Sci U S
A. 2003 Aug 19;100(17):9991-6.
\end{References}
\inputencoding{utf8}
\HeaderA{getPS1sample}{PS score calculation for a given sample}{getPS1sample}
\keyword{PS}{getPS1sample}
%
\begin{Description}\relax
This is an internal function to calculate PS (Prediction Strength) for a given sample.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getPS1sample(vdat, PSpars)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{vdat}] a numeric vector of one sample with multiple selected features

\item[\code{PSpars}] a PS parameter matrix, which rows are the features with the same order as in vdat, 
and the columns are the mean of two group means and weight for each feature
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
PS calculation is based on Golub 1999. In this package, we use four steps to calculate PS scores, 
and this function is for the very last step. 
The four steps are: a) apply "standardize" to standardize input data matrix for each feature; 
b) apply "getTrainingWeights" to select features and return weights for these features; 
c) apply "getMeanOfGroupMeans" to get mean of group means for each selected feature; 
d) use "apply" function to get PS for all samples with this current function "getPS1sample".
NA is ignored for PS calculation.
\end{Details}
%
\begin{Value}
PS score for a single sample
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
TR Golub, DK Slonim, P Tamayo, C Huard, M Gaasenbeek, JP Mesirov, H Coller, ML Loh, JR Downing, MA Caligiuri, et al.
Molecular classification of cancer: class discovery and class prediction by gene expression monitoring
Science, 286 (1999), pp. 531-537
\end{References}
\inputencoding{utf8}
\HeaderA{getTrainingParas}{Feature selection and their weight calculation for PRPS approach}{getTrainingParas}
\keyword{feature}{getTrainingParas}
\keyword{selection}{getTrainingParas}
\keyword{weight}{getTrainingParas}
%
\begin{Description}\relax
this is a wrap up function to select traits, get their weights, and mean and sd for each group based on training data
for each selected feature
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getTrainingParas(trainDat, selectedTraits = NULL, groupInfo,
  refGroup = 0, weightMethod = c("ttest", "limma", "PearsonR",
  "SpearmanR", "MannWhitneyU"), topN = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{trainDat}] training data set, a data matrix or a data frame, samples are in columns, 
and features/traits are in rows

\item[\code{selectedTraits}] a selected trait list if available

\item[\code{groupInfo}] a known group classification, which order should be the same as in colnames of trainDat

\item[\code{refGroup}] the code for reference group, default is 0, but it can be a string or other number, 
which will be changed to 0 within the function

\item[\code{weightMethod}] a string to indicate weight calculation method, there are five choices: 
"limma" for for limma linear model based t value,"ttest" for t test based t value, 
"MannWhitneyU" for Mann Whitney U based rank-biserial,"PearsonR" for Pearson correlation coefficient,
"SpearmanR" for Spearman correlation coefficient, and the defualt value is "ttest"

\item[\code{topN}] an integer to indicate how many top features to be selected
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Within the five weight calculation methods, "limma","ttest", "PearsonR","SpearmanR" are often used and nothing 
is changed for them from usual setting in this function. We describe more detail about "MannWhitneyU" here. 
Mann-Whitney U test is a well known rank based two group comparison test method, but its statistics value U is not easy 
to use for weight. U can be calculated in two different ways depending on which group we stand for. 
Assuming that there are two groups with sample sizes n1 and n2, and rank sum for the two groups are R1 and R2, 
then we can have the following two U values:
\eqn{ U_1 = R_1 - n_1(n_1 + 1)/2}{}
\eqn{ U_2 = R_2 - n_2(n_2 + 1)/2}{}
In this function, we use the test group (non reference group) to calculate U value, and then calculate 
its rank-biserial correlation with the following formula:
\eqn{ r = 1 - 2U/(n_1 * n_2)}{}
P value for "MannWhitneyU", however, is still based on standard Mann - Whitney U test.
NA is ignored before testing.
\end{Details}
%
\begin{Value}
A data frame with all selected features, their means and sds for two groups
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Smyth, G. K. (2004). Linear models and empirical Bayes methods for assessing differential expression in microarray experiments. 
Statistical Applications in traittics and Molecular Biology, Volume 3, Article 3. http://www.statsci.org/smyth/pubs/ebayes.pdf

Wendt, H.W. (1972). "Dealing with a common problem in social science: A simplified rank-biserial coefficient of correlation 
based on the U statistic". European Journal of Social Psychology. 2 (4): 463–465. doi:10.1002/ejsp.2420020412.
\end{References}
\inputencoding{utf8}
\HeaderA{getTrainingWeights}{Feature selection and their weight calculation for PS, LPS and PRPS approaches}{getTrainingWeights}
\keyword{feature}{getTrainingWeights}
\keyword{selection}{getTrainingWeights}
\keyword{weight}{getTrainingWeights}
%
\begin{Description}\relax
this is a wrap up function to select traits, and get their weights for each selected feature
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getTrainingWeights(trainDat, selectedTraits = NULL, groupInfo,
  refGroup = 0, topN = NULL, FDRcut = 0.1,
  weightMethod = c("ttest", "limma", "PearsonR", "SpearmanR",
  "MannWhitneyU"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{trainDat}] training data set, a data matrix or a data frame, samples are in columns, 
and features/traits are in rows

\item[\code{selectedTraits}] a selected trait list if available

\item[\code{groupInfo}] a known group classification, which order should be the same as in colnames of trainDat

\item[\code{refGroup}] the code for reference group, default is 0, but it can be a string or other number, 
which will be changed to 0 within the function

\item[\code{topN}] an integer to indicate how many top features to be selected

\item[\code{FDRcut}] FDR cutoff for feature selection

\item[\code{weightMethod}] a string to indicate weight calculation method, there are five choices: 
"limma" for for limma linear model based t value,"ttest" for t test based t value, 
"MannWhitneyU" for Mann Whitney U based rank-biserial,"PearsonR" for Pearson correlation coefficient,
"SpearmanR" for Spearman correlation coefficient, and the defualt value is "ttest"
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Within the five weight calculation methods, "limma","ttest", "PearsonR","SpearmanR" are often used and nothing 
is changed for them from usual setting in this function. We describe more detail about "MannWhitneyU" here. 
Mann-Whitney U test is a well known rank based two group comparison test method, but its statistics value U is not easy 
to use for weight. U can be calculated in two different ways depending on which group we stand for. 
Assuming that there are two groups with sample sizes n1 and n2, and rank sum for the two groups are R1 and R2, 
then we can have the following two U values:
\eqn{ U_1 = R_1 - n_1(n_1 + 1)/2}{}
\eqn{ U_2 = R_2 - n_2(n_2 + 1)/2}{}
In this function, we use the test group (non reference group) to calculate U value, and then calculate 
its rank-biserial correlation with the following formula:
\eqn{ r = 1 - 2U/(n_1 * n_2)}{}
P value for "MannWhitneyU", however, is still based on standard Mann - Whitney U test.
NA is ignored before testing.
\end{Details}
%
\begin{Value}
A data frame of selected features' parameters such as weights and FDR
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Smyth, G. K. (2004). Linear models and empirical Bayes methods for assessing differential expression in microarray experiments. 
Statistical Applications in traittics and Molecular Biology, Volume 3, Article 3. http://www.statsci.org/smyth/pubs/ebayes.pdf
Wendt, H.W. (1972). "Dealing with a common problem in social science: A simplified rank-biserial coefficient of correlation 
based on the U statistic". European Journal of Social Psychology. 2 (4): 463–465. doi:10.1002/ejsp.2420020412.
\end{References}
\inputencoding{utf8}
\HeaderA{imputeNAs}{NA value imputation}{imputeNAs}
\keyword{NA}{imputeNAs}
\keyword{impute}{imputeNAs}
%
\begin{Description}\relax
This function is to impute NA values if there are any NA in the data. 
Without this step, NAs will cause a lot of troubles in classification score calculation, and therefore, we have to ignore NAs.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
imputeNAs(dataIn, byrow = TRUE, imputeValue = c("median", "mean"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{dataIn}] a data matrix or a data frame, samples are in columns, and features/genes are in rows

\item[\code{byrow}] although we recommend to impute NAs along with features, but this function can be used for either direction,
the default value is byrow = TRUE

\item[\code{imputeValue}] for classification, the most non-informatic value is median/mean in a given row/column, 
so there are two choices for the imputed values: median or mean when NAs are excluded, the default value is "median"
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
During the classification score calculation process, NA offen causes troubles especially when matrix multiplication is involved. 
To avoid this problem, we suggest to impute NA values before any other functions are called if you have NA in your data. 
For classification purpose, the median value is believed to be most noninformative value, so we use median to replace NA. Further more, 
we prefer to do feature-wise median replacement although this function can be applied in both feature wise and sample wise replacements.
\end{Details}
%
\begin{Value}
Same data matrix or data frame as input except that the NA values are imputed.
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
\inputencoding{utf8}
\HeaderA{LPSClassWithPriors}{LPS score calculation for a testing data set without LPStraining output object, but with some priors}{LPSClassWithPriors}
\keyword{LPS}{LPSClassWithPriors}
%
\begin{Description}\relax
This is the function to calculate LPS (Linear Prediction Score) scores for a testing data set 
without LPS training object. However, we do need some prior information such as selected feature list with their weights, 
LPS score means and sds for two groups or priors for two groups' percentages.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
LPSClassWithPriors(newdat, weights, testGroup, refGroup,
  LPSMeanSds = NULL, ratioPriors = c(0.5, 0.5),
  isTestGroupHighLPS = TRUE, standardization = FALSE,
  classProbCut = 0.8, imputeNA = FALSE, byrow = TRUE,
  imputeValue = c("median", "mean"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{newdat}] a new data matrix or data frame, which is comparable to training data set, 
with columns for samples and rows for features

\item[\code{weights}] a numeric vector with selected features (as names of the vector) and their weights

\item[\code{testGroup}] A string for test group name

\item[\code{refGroup}] A string for reference group name

\item[\code{LPSMeanSds}] A numeric vector with 4 items for LPS score distributions: test group mean, reference group mean, test group sd, reference group sd
the names for these items are not necessary, but the order of these items are important

\item[\code{ratioPriors}] A numeric vector with 2 items, ratio prior for test group, and ratio prior for reference group. The order is important

\item[\code{isTestGroupHighLPS}] A logic variable to indicate if the test group has higher LPS score than the reference group

\item[\code{standardization}] a logic variable to indicate if standardization is needed before classification 
score calculation

\item[\code{classProbCut}] a numeric variable within (0,1), which is a cutoff of Empirical Bayesian probability, 
often used values are 0.8 and 0.9, default value is 0.8. Only one value is used for both groups, 
the samples that are not included in either group will be assigned as UNCLASS

\item[\code{imputeNA}] a logic variable to indicate if NA imputation is needed, if it is TRUE, NA imputation is 
processed before any other steps, the default is FALSE

\item[\code{byrow}] a logic variable to indicate direction for imputation, default is TRUE, 
which will use the row data for imputation

\item[\code{imputeValue}] a character variable to indicate which value to be used to replace NA, default is "median", 
the median value of the chose direction with "byrow" data to be used
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This is the function to calculate LPS scores and make classification and 
Empirical Bayesian probabilities for a testing new data set. However, this new data set should be 
comparable to the training data set that generates prior parameters as much as possible. When the testing data set is not comparable
to the training data set, calibration might be needed before calling this function. 
Within this LPStesting function, standardization step is included as an option to minimize the difference 
between training and testing data sets, be aware that standardization step should be consistent between training and testing data sets. 
Also, be aware that this step is only done to make distributions of each selected
features comparable. Be aware that this feature-wise standardization cannot make the sample-wise distributions
comparable. For example, the training data set must have two classification groups, however, 
the proportion of one group sample might be much less than the other group in the testing data set 
compared to the training data set, or even worse, the testing data set might only contain one classification 
group only. This is the common problem for classification and feature-wise standardization cannot solve the problem. 
In order to solve the problem, we should make data comparable as much as possbile before classification step, for example, calibration as mentioned above. 
LPS calculation is based on Wright 2003. The fomula is straightforward:
\eqn{LPS(X) = \sum a_j x_ij}{}
Here a\_j represents the jth selected feature weights, and x\_ij is the corresponding feature value for the ith sample.
\eqn{PRPS(X_i) = \sum (|a_j| log(P1(x_ij)/P0(x_ij)))}{}
When calculate a Empirical Bayes' probability, the 1st group in the input mean and sd vectors is treated as the 
test group. When calculate the probabilities, we first calcualte probability that a sample belongs to either group,
and then use the following formula to get Empirical Bayes' probability:
\eqn{prob(x) = p_test(x)/(p_test(x) + p_ref(x))}{}
Here prob(x) is the Empirical Bayes' probability of a given sample, p\_test(x) is the probability that a given sample
belongs to the test group, p\_ref(x) is the probability that a given sample belongs to the reference group.
Notice that the test and reference group is just the relative grouping, in fact, for this step, we often need
to calculate Empirical Bayes' probabilities for a given sample from two different standing points.
\end{Details}
%
\begin{Value}
A data frame with LPS score, Empirical Bayesian probabilites for two groups and classification
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Wright G, Tan B, Rosenwald A, Hurt EH, Wiestner A, Staudt LM. A gene expression-based method
to diagnose clinically distinct subgroups of diffuse large B cell lymphoma. Proc Natl Acad Sci U S
A. 2003 Aug 19;100(17):9991-6.
\end{References}
\inputencoding{utf8}
\HeaderA{LPStesting}{LPS score calculation for a testing new data set}{LPStesting}
\keyword{LPS}{LPStesting}
%
\begin{Description}\relax
This is the function to calculate LPS (Linear Prediction Score) scores for a testing data set 
with LPS training object. The selected feature list, these features' parameters 
are from the given LPS training object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
LPStesting(LPStrainObj, newdat, standardization = FALSE,
  classProbCut = 0.8, imputeNA = FALSE, byrow = TRUE,
  imputeValue = c("median", "mean"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{newdat}] a new data matrix or data frame, which is comparable to training data set, 
with columns for samples and rows for features

\item[\code{standardization}] a logic variable to indicate if standardization is needed before classification 
score calculation

\item[\code{classProbCut}] a numeric variable within (0,1), which is a cutoff of Empirical Bayesian probability, 
often used values are 0.8 and 0.9, default value is 0.8. Only one value is used for both groups, 
the samples that are not included in either group will be assigned as UNCLASS

\item[\code{imputeNA}] a logic variable to indicate if NA imputation is needed, if it is TRUE, NA imputation is 
processed before any other steps, the default is FALSE

\item[\code{byrow}] a logic variable to indicate direction for imputation, default is TRUE, 
which will use the row data for imputation

\item[\code{imputeValue}] a character variable to indicate which value to be used to replace NA, default is "median", 
the median value of the chose direction with "byrow" data to be used

\item[\code{PStraingObj}] a LPS training object, which is the output from function LPStraining
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This is the function to calculate LPS scores and make classification and 
Empirical Bayesian probabilities for a testing new data set. However, this new data set should be 
comparable to the training data set as much as possible. Within LPStraining and within this current 
LPStesting functions, standardization step is included as an option to minimize the difference 
between training and testing data sets, but this step is only done to make distributions of each selected
features comparable. Be aware that this feature-wise standardization cannot make the sample-wise distributions
comparable. For example, the training data set must have two classification groups, however, 
the proportion of one group sample might be much less than the other group in the testing data set 
compared to the training data set, or even worse, the testing data set might only contain one classification 
group only. This is the common problem for classification and feature-wise standardization cannot solve the problem. 
In order to solve the problem, we should make data comparable as much as possbile before classification step. 
For example, use the same pre-processing settings and make suitable batch effect correction. 
For classification with LPS approach, we also suggest to combine traing and testing data together as "newdat" 
for this LPStesting function, to avoid forcing two groups' classification while there is actual only one group
in the testing group.
LPS calculation is based on Wright 2003. The fomula is straightforward:
\eqn{LPS(X) = \sum a_j x_ij}{}
Here a\_j represents the jth selected feature weights, and x\_ij is the corresponding feature value for the ith sample.
\eqn{PRPS(X_i) = \sum (|a_j| log(P1(x_ij)/P0(x_ij)))}{}
When calculate a Empirical Bayes' probability, the 1st group in the input mean and sd vectors is treated as the 
test group. When calculate the probabilities, we first calcualte probability that a sample belongs to either group,
and then use the following formula to get Empirical Bayes' probability:
\eqn{prob(x) = p_test(x)/(p_test(x) + p_ref(x))}{}
Here prob(x) is the Empirical Bayes' probability of a given sample, p\_test(x) is the probability that a given sample
belongs to the test group, p\_ref(x) is the probability that a given sample belongs to the reference group.
Notice that the test and reference group is just the relative grouping, in fact, for this step, we often need
to calculate Empirical Bayes' probabilities for a given sample from two different standing points.
\end{Details}
%
\begin{Value}
A data frame with LPS score, Empirical Bayesian probabilites for two groups and classification
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Wright G, Tan B, Rosenwald A, Hurt EH, Wiestner A, Staudt LM. A gene expression-based method
to diagnose clinically distinct subgroups of diffuse large B cell lymphoma. Proc Natl Acad Sci U S
A. 2003 Aug 19;100(17):9991-6.
\end{References}
\inputencoding{utf8}
\HeaderA{LPStraining}{Feature selection, parameter estimation, and LPS calculation for training data set}{LPStraining}
\keyword{LPS}{LPStraining}
\keyword{limma}{LPStraining}
\keyword{training}{LPStraining}
\keyword{weight}{LPStraining}
%
\begin{Description}\relax
This is the wrap up function to select top features, estimate parameters, and calculate LPS (Linear Prediction Score) scores 
based on a given training data set.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
LPStraining(trainDat, standardization = FALSE, selectedTraits = NULL,
  groupInfo, refGroup = 0, topN = NULL, FDRcut = 0.1,
  weightMethod = c("ttest", "limma", "PearsonR", "SpearmanR",
  "MannWhitneyU"), classProbCut = 0.8, imputeNA = FALSE,
  byrow = TRUE, imputeValue = c("median", "mean"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{trainDat}] training data set, a data matrix or a data frame, samples are in columns, and features/traits are in rows

\item[\code{selectedTraits}] a selected trait list if available

\item[\code{groupInfo}] a known group classification, which order should be the same as in colnames of trainDat

\item[\code{refGroup}] the code for reference group, default is 0, but it can be a string or other number, which will be 
changed to 0 within the function

\item[\code{topN}] an integer to indicate how many top features to be selected

\item[\code{FDRcut}] a FDR cutoff to select top features, which is only valid when topN is set as defaul NULL, 
all features will be returned if both topN and FDRcut are set as default NULL

\item[\code{weightMethod}] a string to indicate weight calculation method, there are five choices: 
"limma" for for limma linear model based t value,"ttest" for t test based t value, 
"MannWhitneyU" for Mann Whitney U based rank-biserial,"PearsonR" for Pearson correlation coefficient,
"SpearmanR" for Spearman correlation coefficient, and the defualt value is "limma"

\item[\code{classProbCut}] a numeric variable within (0,1), which is a cutoff of Empirical Bayesian probability, 
often used values are 0.8 and 0.9, default value is 0.8. Only one value is used for both groups, 
the samples that are not included in either group will be assigned as UNCLASS

\item[\code{imputeNA}] a logic variable to indicate if NA imputation is needed, if it is TRUE, 
NA imputation is processed before any other steps, the default is FALSE

\item[\code{byrow}] a logic variable to indicate direction for imputation, default is TRUE, 
which will use the row data for imputation

\item[\code{imputeValue}] a character variable to indicate which value to be used to replace NA, default is "median", 
the median value of the chose direction with "byrow" data to be used
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
LPS calculation is based on Wright 2003. The fomula is straightforward:
\eqn{LPS(X) = \sum a_j x_ij}{}
Here a\_j represents the jth selected feature weights, and x\_ij is the corresponding feature value 
for the ith sample.
In this wrap up function, we use three steps to calculate LPS scores and classification. 
Before these three steps, we also give an option for NA imputation and for standardization for each feature. 
The three steps are:
a) apply "getTrainingWeights" to select features and return weights for these features;
b) use "apply" function to get LPS classification scores and Empirical Bayes' probabilites for all samples;
When we calculate a Empirical Bayes' probability, the 1st group in the input mean and sd vectors is treated 
as the test group. When we calculate the probabilities, we first calcualte probability that a sample belongs
to either group, and then use the following formula to get Empirical Bayes' probability:
\eqn{prob(x) = p_test(x)/(p_test(x) + p_ref(x))}{}
Here prob(x) is the Empirical Bayes' probability of a given sample, p\_test(x) is the probability 
that a given sample belongs to the test group, p\_ref(x) is the probability that a given sample 
belongs to the reference group.
Notice that the test and reference group is just the relative grouping, in fact, for this step, 
we often need to calculate Empirical Bayes' probabilities for a given sample from two different standing points.
c) . This function also give classification for the training group and confusion matrix to compare 
LPS classification with original group info for training data set.
If NAs are not imputed, they are ignored for feature selection, weight calculation, LPS parameter estimation, 
and LPS calculation.
\end{Details}
%
\begin{Value}
A list with four items is returned: LPS parameters for selected features, LPS scores and classifications for training samples, and confusion matrix to compare classification based on LPS scores and original classification.
\begin{ldescription}
\item[\code{LPS\_pars}] a list of 2 items, the 1st item is a data frame with weights and group testing results of each selected features for LPS calculation, and the 2nd item is a numeric vector containing LPS mean and sd for two groups
\item[\code{LPS\_train}] a data frame of LPS score, true classification, Empirical Bayesian probabilites for both groups, and its classification for all training samples, notice that the classification is based on probabilities instead of LPS scores, and there is UNCLASS group besdies the given two groups
\item[\code{classCompare}] a confusion matrix list object that compare LPS classification based on selected features and weights compared to input group classification for training data set, notice that the samples with UNCLASS are excluded since confusion matrix can not compare 3 groups to 2 groups
\item[\code{classTable}] a table to display comparison of LPS classification based on selected features and weights compared to input group classification for training data set. Since UNCLASS is excluded from confusion matrix, add this table for full comparison
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Wright G, Tan B, Rosenwald A, Hurt EH, Wiestner A, Staudt LM. A trait expression-based method
to diagnose clinically distinct subgroups of diffuse large B cell lymphoma. Proc Natl Acad Sci U S
A. 2003 Aug 19;100(17):9991-6.
\end{References}
\inputencoding{utf8}
\HeaderA{plotROC}{ROC curve with AUC, Youden best and natural cutoff of 0}{plotROC}
\keyword{ROC}{plotROC}
%
\begin{Description}\relax
This is an internal function to plot ROC (Receiver operating characteristic) curve showing AUC, Youden best and natural cutoff of 0 points.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotROC(contdat, contname, catdat, catname, xshift = -0.05,
  yshift = 0.02)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{contdat}] a vector of a continuous variable

\item[\code{contname}] a string to show name of a continuous vector

\item[\code{catdat}] a vector of a dichotomous variable

\item[\code{catname}] a string to show name of a  dichotomous variable

\item[\code{xshift}] a numeric variable to indicate how much value shift along x-axis to move the label position for the natural 0 cutoff point,
default value is -0.05

\item[\code{yshift}] a numeric variable to indicate how much value shift along y-axis to move the label position for the natural 0 cutoff point,
default value is 0.02
\end{ldescription}
\end{Arguments}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
\inputencoding{utf8}
\HeaderA{plotTesting}{Plot function for testing objects}{plotTesting}
\keyword{hist,}{plotTesting}
\keyword{plot}{plotTesting}
\keyword{scatter}{plotTesting}
%
\begin{Description}\relax
This is to plot hist for a given testing object, and scatter plot if the testing object is from LPStesting or PRPStesting
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotTesting(testObj, plotName, breaks = 30)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{testObj}] a testing object from LPStesting, or PRPStesting, or PStesting

\item[\code{breaks}] a integer to indicate how many cells in the histogram

\item[\code{plotNanme}] a string variable to indicate the file name to save, it should includes path and plot file name (without .pdf part)
\end{ldescription}
\end{Arguments}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
\inputencoding{utf8}
\HeaderA{plotTraining}{Plot function for training objects}{plotTraining}
\keyword{ROC,}{plotTraining}
\keyword{hist,}{plotTraining}
\keyword{plot}{plotTraining}
\keyword{scatter}{plotTraining}
%
\begin{Description}\relax
This is to plot ROC and hist for a given training object, and scatter plot if the training object us from LPStraining or PRPStraining
\end{Description}
%
\begin{Usage}
\begin{verbatim}
plotTraining(trainObj, plotName, xshift = -0.05, yshift = 0.02,
  breaks = 30)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{trainObj}] a training object from LPStraining, or PRPStraining, or PStraining

\item[\code{xshift}] a numeric variable to indicate how much value shift along x-axis to move the label position for the natural 0 cutoff point,
default value is -0.05, which is used for ROC plot

\item[\code{yshift}] a numeric variable to indicate how much value shift along y-axis to move the label position for the natural 0 cutoff point,
default value is 0.02, which is used for ROC plot

\item[\code{breaks}] a integer to indicate how many cells in the histogram

\item[\code{plotNanme}] a string variable to indicate the file name to save, it should includes path and plot file name (without .pdf part)
\end{ldescription}
\end{Arguments}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
\inputencoding{utf8}
\HeaderA{PRPStesting}{PRPS score calculation for a testing new data set}{PRPStesting}
\keyword{PRPS}{PRPStesting}
%
\begin{Description}\relax
This is the function to calculate PRPS (Probability ratio based classification predication score)
scores for a testing data set with PRPS training object. The selected feature list, 
these features' parameters are from the given PRPS training object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PRPStesting(PRPStrainObj, newdat, standardization = FALSE,
  classProbCut = 0.8, imputeNA = FALSE, byrow = TRUE,
  imputeValue = c("median", "mean"), isCompToTrain = TRUE,
  group1ratioPrior = 1/2)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{newdat}] a new data matrix or data frame, which is comparable to training data set, 
with columns for samples and rows for features

\item[\code{standardization}] a logic variable to indicate if standardization is needed before classification 
score calculation

\item[\code{classProbCut}] a numeric variable within (0,1), which is a cutoff of Empirical Bayesian probability, 
often used values are 0.8 and 0.9, default value is 0.8. Only one value is used for both groups, 
the samples that are not included in either group will be assigned as UNCLASS

\item[\code{imputeNA}] a logic variable to indicate if NA imputation is needed, if it is TRUE, NA imputation is 
processed before any other steps, the default is FALSE

\item[\code{byrow}] a logic variable to indicate direction for imputation, default is TRUE, 
which will use the row data for imputation

\item[\code{imputeValue}] a character variable to indicate which value to be used to replace NA, default is "median", 
the median value of the chose direction with "byrow" data to be used

\item[\code{isCompToTrain}] a logic variable to indicate if testing data set is comparable to the training data set, if so, 
group mean and sd values from PRPStraingObj are used for each selected feature

\item[\code{group1ratioPrior}] a prior of two group ratio (test group over reference group) that is used to calculate
group mean and sd values for each selected feature when isCompToTrain is set as FALSE

\item[\code{PStraingObj}] a PRPS training object, which is the output from function PRPStraining
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This is the function to calculate PRPS scores and make classification and Empirical Bayesian 
probabilities for a testing new data set. However, this new data set should be comparable to 
the training data set as much as possible. Within PRPStraining and within this current PRPStesting functions, 
standardization step is included as an option to minimize the difference between training and testing data sets, 
but this step is only done to make distributions of each selected features comparable. 
Be aware that this feature-wise standardization cannot make the sample-wise distributions comparable. 
For example, the training data set must have two classification groups, however, the proportion of one group sample
might be much less than the other group in the testing data set compared to the training data set, or even worse, 
the testing data set might only contain one classification group only. This is the common problem for classification 
and feature-wise standardization cannot solve the problem. 
In order to solve the problem, we should make data comparable as much as possbile before classification step. 
For example, use the same pre-processing settings and make suitable batch effect correction. 
For classification with PRPS approach, we also suggest to combine traing and testing data together as "newdat" 
for this PRPStesting function, to avoid forcing two groups' classification while there is actual only one group
in the testing group.
However, if we know that the testing and training data sets are not comparable, we should set isCompToTrain as
FALSE and choose an approoriate group1ratioPrior as a prior for PRPS score calculation. 
PRPS calculation is based on Ennishi 2018. The fomula is 
\eqn{PRPS(X) = \sum a_j x_ij}{}
Here, a\_j represents the jth selected feature weights, and x\_ij is the corresponding feature value for the ith sample, P1 and P0 are the probabilities that the ith sample belongs to two different group.
When calculate a Empirical Bayes' probability, the 1st group in the input mean and sd vectors is treated as
the test group. When calculate the probabilities, we first calcualte probability that a sample belongs to either group, 
and then use the following formula to get Empirical Bayes' probability:
\eqn{prob(x) = p_test(x)/(p_test(x) + p_ref(x))}{}
Here prob(x) is the Empirical Bayes' probability of a given sample, p\_test(x) is the probability that a given sample 
belongs to the test group, p\_ref(x) is the probability that a given sample belongs to the reference group.
Notice that the test and reference group is just the relative grouping, in fact, for this step, 
we often need to calculate Empirical Bayes' probabilities for a given sample from two different standing points.
\end{Details}
%
\begin{Value}
A data frame with PRPS scores, Empirical Bayesian probabilites for two groups and classification, and classification based on 0 natural cutoff on PRPS scores.
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Ennishi D, Jiang A, Boyle M, Collinge B, Grande BM, Ben-Neriah S, Rushton C, Tang J, Thomas N, Slack GW, Farinha P, 
Takata K, Miyata-Takata T, Craig J, Mottok A, Meissner B, Saberi S, Bashashati A, Villa D, Savage KJ, Sehn LH, Kridel R,
Mungall AJ, Marra MA, Shah SP, Steidl C, Connors JM, Gascoyne RD, Morin RD, Scott DW. 
Double-Hit Trait Expression Signature Defines a Distinct Subgroup of Germinal Center B-Cell-Like Diffuse Large B-Cell
Lymphoma. J Clin Oncol. 2018 Dec 3:JCO1801583. doi: 10.1200/JCO.18.01583.
\end{References}
\inputencoding{utf8}
\HeaderA{PRPStraining}{Feature selection, parameter estimation, and PRPS calculation for training data set}{PRPStraining}
\keyword{PRPS}{PRPStraining}
\keyword{limma}{PRPStraining}
\keyword{training}{PRPStraining}
\keyword{weight}{PRPStraining}
%
\begin{Description}\relax
This is the wrap up function to select top features, estimate parameters, and calculate PRPS (Probability
ratio based classification predication score) scores based on a given training data set.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PRPStraining(trainDat, standardization = FALSE, selectedTraits = NULL,
  groupInfo, refGroup = 0, topN = NULL, FDRcut = 0.1,
  weightMethod = c("ttest", "limma", "PearsonR", "SpearmanR",
  "MannWhitneyU"), classProbCut = 0.8, imputeNA = FALSE,
  byrow = TRUE, imputeValue = c("median", "mean"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{trainDat}] training data set, a data matrix or a data frame, samples are in columns, and features/traits are in rows

\item[\code{selectedTraits}] a selected trait list if available

\item[\code{groupInfo}] a known group classification, which order should be the same as in colnames of trainDat

\item[\code{refGroup}] the code for reference group, default is 0, but it can be a string or other number, which will be 
changed to 0 within the function

\item[\code{topN}] an integer to indicate how many top features to be selected

\item[\code{FDRcut}] a FDR cutoff to select top features, which is only valid when topN is set as defaul NULL, 
all features will be returned if both topN and FDRcut are set as default NULL

\item[\code{weightMethod}] a string to indicate weight calculation method, there are five choices: 
"limma" for for limma linear model based t value,"ttest" for t test based t value, 
"MannWhitneyU" for Mann Whitney U based rank-biserial,"PearsonR" for Pearson correlation coefficient,
"SpearmanR" for Spearman correlation coefficient, and the defualt value is "limma"

\item[\code{classProbCut}] a numeric variable within (0,1), which is a cutoff of Empirical Bayesian probability, 
often used values are 0.8 and 0.9, default value is 0.8. Only one value is used for both groups, 
the samples that are not included in either group will be assigned as UNCLASS

\item[\code{imputeNA}] a logic variable to indicate if NA imputation is needed, if it is TRUE, 
NA imputation is processed before any other steps, the default is FALSE

\item[\code{byrow}] a logic variable to indicate direction for imputation, default is TRUE, 
which will use the row data for imputation

\item[\code{imputeValue}] a character variable to indicate which value to be used to replace NA, default is "median", 
the median value of the chose direction with "byrow" data to be used
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
PRPS calculation is based on Ennishi 2018, its formula is:
\eqn{PRPS(X_i) = \sum (|a_j| log(P1(x_ij)/P0(x_ij)))}{}
Here, a\_j represents the jth selected feature weights, and x\_ij is the corresponding feature value
for the ith sample, 
P1 and P0 are the probabilities that the ith sample belongs to two different group.
In this wrap up function, we use three steps to calculate PRPS scores and classification. 
Before these three steps, we also give an option for NA imputation and for standardization for each feature. 
The three steps are:
a) Apply "getTrainingWeights" to select features and return weights for these features.
b) Use "apply" function to get PRPS classification scores and Empirical Bayes' probabilites for all samples.
When we calculate a Empirical Bayes' probability, the 1st group in the input mean and sd vectors is treated
as the test group. 
When we calculate the probabilities, we first calcualte probability that a sample belongs to either group, 
and then use the 
following formula to get Empirical Bayes' probability:
\eqn{prob(x) = p_test(x)/(p_test(x) + p_ref(x))}{}
Here prob(x) is the Empirical Bayes' probability of a given sample, p\_test(x) is the probability
that a given sample belongs to the test group, p\_ref(x) is the probability that a given sample belongs
to the reference group.
Notice that the test and reference group is just the relative grouping, in fact, for this step, 
we often need to calculate Empirical Bayes' probabilities for a given sample from two different standing points.
c) This function also give classification for the training group and confusion matrix to compare PRPS classification
with original group info for training data set.
If NAs are not imputed, they are ignored for feature selection, weight calculation, PRPS parameter estimation, 
and PRPS calculation.
\end{Details}
%
\begin{Value}
A list with three items is returned: PRPS parameters for selected features, PRPS scores and classifications for training samples, and confusion matrix to compare classification based on PRPS scores and original classification.
\begin{ldescription}
\item[\code{PRPS\_pars}] a list of 3 items, the 1st item is a data frame with weights and group testing results of each selected features for PRPS calculation, the 2nd item is a numeric vector containing PRPS mean and sd for two groups，and the 3rd item is a data frame contains mean and sd for each group and for each selected feature
\item[\code{PRPS\_train}] a data frame of PRPS score, true classification, Empirical Bayesian probabilites for both groups, and its classification for all training samples, notice that there are two ways for classifications, one is based on probabilities, and there is UNCLASS group besdies the given two groups, alternatively, the other one is based on PRPS scores directly and 0 treated as a natural cutoff
\item[\code{classCompare}] a confusion matrix list object that compare PRPS classification based on selected features and weights compared to input group classification for training data set, notice that the samples with UNCLASS are excluded since confusion matrix can not compare 3 groups to 2 groups
\item[\code{classTable}] a table to display comparison of PRPS classification based on selected features and weights compared to input group classification for training data set. Since UNCLASS is excluded from confusion matrix, add this table for full comparison
\end{ldescription}
\end{Value}
%
\begin{References}\relax
Ennishi D, Jiang A, Boyle M, Collinge B, Grande BM, Ben-Neriah S, Rushton C, Tang J, Thomas N, Slack GW, Farinha P, 
Takata K, Miyata-Takata T, Craig J, Mottok A, Meissner B, Saberi S, Bashashati A, Villa D, Savage KJ, Sehn LH, Kridel R, 
Mungall AJ, Marra MA, Shah SP, Steidl C, Connors JM, Gascoyne RD, Morin RD, Scott DW. Double-Hit Gene Expression Signature Defines
a Distinct Subgroup of Germinal Center B-Cell-Like Diffuse Large B-Cell Lymphoma. J Clin Oncol. 
2018 Dec 3:JCO1801583. doi: 10.1200/JCO.18.01583.
\end{References}
\inputencoding{utf8}
\HeaderA{PStesting}{PS score calculation for a testing new data set}{PStesting}
\keyword{PS}{PStesting}
%
\begin{Description}\relax
This is the function to calculate PS (Prediction Strength) scores for a testing data set
with PS training object. The selected feature list, these features' parameters are 
from the given PS training object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PStesting(PStrainObj, newdat, imputeNA = FALSE, byrow = TRUE,
  imputeValue = c("median", "mean"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{newdat}] a new data matrix or data frame, which is comparable to training data set, 
with columns for samples and rows for features

\item[\code{imputeNA}] a logic variable to indicate if NA imputation is needed, if it is TRUE, NA imputation is 
processed before any other steps, the default is FALSE

\item[\code{byrow}] a logic variable to indicate direction for imputation, default is TRUE, 
which will use the row data for imputation

\item[\code{imputeValue}] a character variable to indicate which value to be used to replace NA, default is "median", 
the median value of the chose direction with "byrow" data to be used

\item[\code{PStraingObj}] a PS training object, which is the output from function PStraining

\item[\code{standardization}] a logic variable to indicate if standardization is needed before classification 
score calculation

\item[\code{classProbCut}] a numeric variable within (0,1), which is a cutoff of Empirical Bayesian probability, 
often used values are 0.8 and 0.9, default value is 0.8. Only one value is used for both groups, 
the samples that are not included in either group will be assigned as UNCLASS
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This is the function to calculate PS scores and make classification for a testing new data set. 
However, this new data set should be comparable to the training data set as much as possible. 
Within PStraining and within this current PStesting functions, standardization step is included
to minimize the difference between training and testing data sets, but this step is only done to
make distributions of each selected features comparable. Be aware that this feature-wise 
standardization cannot make the sample-wise distributions comparable. 
For example, the training data set must have two classification groups, however, the proportion of 
one group sample might be much less than the other group in the testing data set compared to the 
training data set, or even worse, the testing data set might only contain one classification group only. 
This is the common problem for classification and feature-wise standardization cannot solve the problem. 
In order to solve the problem, we should make data comparable as much as possbile before classification step.
For example, use the same pre-processing settings and make suitable batch effect correction. 
For classification with PS approach, we also suggest to combine traing and testing data together as "newdat"
for this PStesting function, to avoid forcing two groups' classification while there is actual only one group
in the testing group.
\end{Details}
%
\begin{Value}
A data frame with PS score and classification
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
TR Golub, DK Slonim, P Tamayo, C Huard, M Gaasenbeek, JP Mesirov, H Coller, ML Loh, JR Downing, MA Caligiuri, et al.
Molecular classification of cancer: class discovery and class prediction by gene expression monitoring
Science, 286 (1999), pp. 531-537
\end{References}
\inputencoding{utf8}
\HeaderA{PStraining}{Feature selection, parameter estimation, and PS calculation for training data set}{PStraining}
\keyword{PS}{PStraining}
\keyword{limma}{PStraining}
\keyword{training}{PStraining}
\keyword{weight}{PStraining}
%
\begin{Description}\relax
This is the wrap up function to select top features, estimate parameters, 
and calculate PS (Prediction Strength) scores based on a given training data set.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PStraining(trainDat, selectedTraits = NULL, groupInfo, refGroup = 0,
  topN = NULL, FDRcut = 0.1, weightMethod = c("ttest", "limma",
  "PearsonR", "SpearmanR", "MannWhitneyU"), imputeNA = FALSE,
  byrow = TRUE, imputeValue = c("median", "mean"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{trainDat}] training data set, a data matrix or a data frame, samples are in columns, and features/traits are in rows

\item[\code{selectedTraits}] a selected trait list if available

\item[\code{groupInfo}] a known group classification, which order should be the same as in colnames of trainDat

\item[\code{refGroup}] the code for reference group, default is 0, but it can be a string or other number, which will be 
changed to 0 within the function

\item[\code{topN}] an integer to indicate how many top features to be selected

\item[\code{FDRcut}] a FDR cutoff to select top features, which is only valid when topN is set as defaul NULL, 
all features will be returned if both topN and FDRcut are set as default NULL

\item[\code{weightMethod}] a string to indicate weight calculation method, there are five choices: 
"limma" for for limma linear model based t value,"ttest" for t test based t value, 
"MannWhitneyU" for Mann Whitney U based rank-biserial,"PearsonR" for Pearson correlation coefficient,
"SpearmanR" for Spearman correlation coefficient, and the defualt value is "limma"

\item[\code{imputeNA}] a logic variable to indicate if NA imputation is needed, if it is TRUE, 
NA imputation is processed before any other steps, the default is FALSE

\item[\code{byrow}] a logic variable to indicate direction for imputation, default is TRUE, 
which will use the row data for imputation

\item[\code{imputeValue}] a character variable to indicate which value to be used to replace NA, default is "median", 
the median value of the chose direction with "byrow" data to be used
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
PS calculation is based on Golub 1999. In this warp up function, we use four steps to calculate 
PS scores and classification. The range of PS scores is [-1,1]. Before these four steps, we also give an option
for NA imputation. The four steps are:
a) apply "standardize" to standardize input data matrix for each feature;
b) apply "getTrainingWeights" to select features and return weights for these features;
c) apply "getMeanOfGroupMeans" to get mean of group means for each selected feature;
d) use "apply" function to get PS scores for all samples with "getPS1sample", the formula is:
\eqn{PS = (V_win − V_lose)/(V_win + V_lose)}{}
Here, where V\_win and V\_lose are the vote totals for the winning and losing features/traits for a given sample
This function also give classification for the training group and confusion matrix to compare PS classification
with original group info for training data set.
If NAs are not imputed, they are ignored for feature selection, weight calculation, PS parameter estimation,
and PS calculation.
\end{Details}
%
\begin{Value}
A list with three items is returned: PS parameters for selected features, PS scores and classifications for training samples, and confusion matrix to compare classification based on PS scores and original classification.
\begin{ldescription}
\item[\code{PS\_pars}] a data frame with all parameters needed for PS calculation for each selected features
\item[\code{PS\_train}] a data frame of PS score, true classification and its classification based on scores for all training samples
\item[\code{classCompare}] a confusion matrix list object that compare PS classification based on selected features and weights compared to input group classification for training data set
\item[\code{classTable}] a table to display comparison of PS classification based on selected features and weights compared to input group classification for training data set
\end{ldescription}
\end{Value}
%
\begin{References}\relax
TR Golub, DK Slonim, P Tamayo, C Huard, M Gaasenbeek, JP Mesirov, H Coller, ML Loh, JR Downing, MA Caligiuri, et al.
Molecular classification of cancer: class discovery and class prediction by gene expression monitoring
Science, 286 (1999), pp. 531-537
\end{References}
\inputencoding{utf8}
\HeaderA{standardize}{A standardization Function}{standardize}
\keyword{standardization}{standardize}
%
\begin{Description}\relax
This function is to standardize data in order to make features or samples be comparable. 
You can to standardize your data either by row or by column.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
standardize(dataIn, byrow = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{dataIn}] a data matrix or a data frame, samples are in columns, and features/genes are in rows

\item[\code{byrow}] although we recommend to standardize data along with features, 
but this function can be used for either direction, the default value is byrow = TRUE
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Standardization is the standard way to make data comparable. For this package, 
this should be done right after imputeNAs if necessary. In general, 
we do not recommend this step before classification, however, if the training and testing data sets
are obviously not comparable, we suggest to standardize training and testing data separately for each gene. 
It should be aware that this step might inflate sample differences for the low expression genes.
Standardization is done as:
\eqn{ X = (X-mean(X))/sd(X) }{}
In this step, NA are removed from mean and sd calculation, which means that this step is safe even imputeNAs is not done before this step when they are NAs in the data.
\end{Details}
%
\begin{Value}
Standardized data matrix or data frame
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
\inputencoding{utf8}
\HeaderA{weightedLogProbClass}{PRPS score calculation for a data set}{weightedLogProbClass}
\keyword{PRPS}{weightedLogProbClass}
%
\begin{Description}\relax
This is usually as an internal function called by PRPStraining, PRPStesting and getClassScores, which is used to actually
calculate PRPS scores However, it can be also called directly.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
weightedLogProbClass(newdat, topTraits, weights, classMeans, classSds)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{newdat}] a new data matrix or data frame, with columns for samples and rows for features

\item[\code{topTraits}] selected features used for PRPS calculation

\item[\code{weights}] feature weights

\item[\code{classMeans}] a numeric vector of two group means, the 1st item is for testing group, 
while the 2nd item is for reference group

\item[\code{classSds}] a numeric vector of two group standard deviations (sds), the 1st item is for testing group, 
while the 2nd item is for reference group
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\#'  PRPS calculation is based on Ennishi 2018. The fomula is 
\eqn{PRPS(X) = \sum a_j x_ij}{}
Here, a\_j represents the jth selected feature weightss, and x\_ij is the corresponding feature value for the ith sample, P1 and P0 are the probabilities that the ith sample belongs to two different group.
When calculate a Empirical Bayes' probability, the 1st group in the input mean and sd vectors is treated as
the test group. 
If there are NAs in the data and not imputed before calling this function, these NAs will be ignored for PRPS score calculation.
If you want to call this function directly, make sure to give all values for its parameters. If you do not have PRPStraining object
but would like to calculate PRPS scores, this is function is much easier to use than PRPStesting, and this function is 
identical if you work on PRPS approach.
\end{Details}
%
\begin{Value}
A numeric vector of PRPS
\end{Value}
%
\begin{Author}\relax
Aixiang Jiang
\end{Author}
%
\begin{References}\relax
Ennishi D, Jiang A, Boyle M, Collinge B, Grande BM, Ben-Neriah S, Rushton C, Tang J, Thomas N, Slack GW, Farinha P, 
Takata K, Miyata-Takata T, Craig J, Mottok A, Meissner B, Saberi S, Bashashati A, Villa D, Savage KJ, Sehn LH, Kridel R, 
Mungall AJ, Marra MA, Shah SP, Steidl C, Connors JM, Gascoyne RD, Morin RD, Scott DW. Double-Hit Gene Expression Signature Defines
a Distinct Subgroup of Germinal Center B-Cell-Like Diffuse Large B-Cell Lymphoma. J Clin Oncol. 
2018 Dec 3:JCO1801583. doi: 10.1200/JCO.18.01583.
\end{References}
\printindex{}
\end{document}
